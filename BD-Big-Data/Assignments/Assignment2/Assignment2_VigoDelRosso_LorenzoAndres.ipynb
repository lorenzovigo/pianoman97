{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "#### First Name: Lorenzo Andrés\n",
    "#### Last Name: Vigo del Rosso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession.builder.appName(\"Twitter Analysis\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = spark.read.json(\"corona_tweet_new.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- in_reply_to_status_id: string (nullable = true)\n",
      " |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- default_profile: boolean (nullable = true)\n",
      " |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- favourites_count: long (nullable = true)\n",
      " |    |-- follow_request_sent: string (nullable = true)\n",
      " |    |-- followers_count: long (nullable = true)\n",
      " |    |-- following: string (nullable = true)\n",
      " |    |-- friends_count: long (nullable = true)\n",
      " |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- is_translator: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- listed_count: long (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- notifications: string (nullable = true)\n",
      " |    |-- profile_background_color: string (nullable = true)\n",
      " |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |-- profile_image_url: string (nullable = true)\n",
      " |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |-- profile_link_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |-- profile_text_color: string (nullable = true)\n",
      " |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |-- protected: boolean (nullable = true)\n",
      " |    |-- screen_name: string (nullable = true)\n",
      " |    |-- statuses_count: long (nullable = true)\n",
      " |    |-- time_zone: string (nullable = true)\n",
      " |    |-- translator_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- utc_offset: string (nullable = true)\n",
      " |    |-- verified: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From the user nestec col select the following cols only id_str,followers_count,friends_count and created at \n",
    "# (2 points)\n",
    "from pyspark.sql.functions import col \n",
    "df_twitter=df_twitter.select(col(\"created_at\"),\n",
    "                             col(\"favorite_count\"),\n",
    "                             col(\"hashtags\"),\n",
    "                             col(\"id\"),\n",
    "                             col(\"in_reply_to_status_id\"),\n",
    "                             col(\"in_reply_to_user_id_str\"),\n",
    "                             col(\"location\"),\n",
    "                             col(\"reply_count\"),\n",
    "                             col(\"retweet_count\"),\n",
    "                             col(\"source\"),\n",
    "                             col(\"user.id_str\").alias(\"user_id_str\"),\n",
    "                             col(\"user.followers_count\").alias(\"user_followers_count\"),\n",
    "                             col(\"user.friends_count\").alias(\"user_friends_count\"),\n",
    "                             col(\"user.created_at\").alias(\"user_created_at\")\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- in_reply_to_status_id: string (nullable = true)\n",
      " |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- user_id_str: string (nullable = true)\n",
      " |-- user_followers_count: long (nullable = true)\n",
      " |-- user_friends_count: long (nullable = true)\n",
      " |-- user_created_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15894"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the total count of number of records in df_twitter(1 point)\n",
    "df_twitter.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|   extracted_source|              source|\n",
      "+-------------------+--------------------+\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web Client|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the source lable from source col by droping the anchor tab and save it as another col named extracted_source\n",
    "# for example <a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a> => Twitter Web App\n",
    "# you can use \"<a [^>]+>([^<]+)\" as regualr expresion and the group would be 1 for this regular expression.\n",
    "#(4 points)\n",
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "df_twitter=df_twitter.withColumn(\"extracted_source\", regexp_extract('source',r'<a [^>]+>([^<]+)', 1)) # Use what's given in the commment  \n",
    "df_twitter.select(col('extracted_source'),col('source')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame into RDD\n",
    "rdd_twitter=df_twitter.rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporay table in memory with name as twitter (1 point)\n",
    "df_twitter.createTempView(\"TWITTER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Data\n",
    "\n",
    "#### You will be writing code to find the answer to the questions listed below using Just RDD, Using spark SQL \n",
    "\n",
    "- Analyze using RDD \n",
    "- Analyze using Dataframe without temp table \n",
    "- Analyze using spark.sql with temp table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Get total number of unique users (1 point for each type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14094"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "rdd_twitter.map(lambda tweet: (tweet[10], 1)).reduceByKey(lambda a, b: a + b).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14094"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.select(\"user_id_str\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|count(DISTINCT user_id_str)|\n",
      "+---------------------------+\n",
      "|                      14094|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql('SELECT COUNT(DISTINCT user_id_str) FROM TWITTER').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Get count of user who have more than 1 tweet in the data (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "rdd_twitter.map(lambda tweet: (tweet[10], 1)).reduceByKey(lambda a, b: a + b).filter(lambda user: user[1] > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.groupby(\"user_id_str\").count().filter(\"count > 1\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1016|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql('SELECT COUNT(*) FROM (SELECT COUNT(user_id_str) AS tweet_count FROM TWITTER GROUP BY user_id_str) WHERE tweet_count > 1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Get total number unique extracted_source (1 point each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "rdd_twitter.map(lambda tweet: (tweet[14], 1)).reduceByKey(lambda a, b: a + b).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.select(\"extracted_source\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|count(DISTINCT extracted_source)|\n",
      "+--------------------------------+\n",
      "|                             133|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql('SELECT COUNT(DISTINCT extracted_source) FROM TWITTER').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Get top 5 most used extracted_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Twitter for Android', 6262),\n",
       " ('Twitter for iPhone', 5698),\n",
       " ('Twitter Web App', 2878),\n",
       " ('Twitter for iPad', 428),\n",
       " ('Twitter Web Client', 136)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD (5 points)\n",
    "rdd_twitter.map(lambda tweet: (tweet[14], 1)).reduceByKey(lambda a, b: a + b).takeOrdered(5, lambda s: -1 * s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|   extracted_source|count|\n",
      "+-------------------+-----+\n",
      "|Twitter for Android| 6262|\n",
      "| Twitter for iPhone| 5698|\n",
      "|    Twitter Web App| 2878|\n",
      "|   Twitter for iPad|  428|\n",
      "| Twitter Web Client|  136|\n",
      "+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using DataFrame (2 points)\n",
    "df_twitter.groupby(\"extracted_source\").count().sort(\"count\", ascending = False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|   extracted_source|count|\n",
      "+-------------------+-----+\n",
      "|Twitter for Android| 6262|\n",
      "| Twitter for iPhone| 5698|\n",
      "|    Twitter Web App| 2878|\n",
      "|   Twitter for iPad|  428|\n",
      "| Twitter Web Client|  136|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table. (2 points)\n",
    "spark.sql('SELECT extracted_source, COUNT(extracted_source) as count FROM TWITTER GROUP BY extracted_source ORDER BY count DESC LIMIT 5').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Get count of distinct hastags used ( 5 point each) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "rdd_twitter.flatMap(lambda tweet: tweet[2]).map(lambda hashtags: (hashtags, 1)).reduceByKey(lambda a, b: a + b).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "import pyspark.sql.functions as functions\n",
    "df_twitter.select(functions.explode(col('hashtags'))).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1215|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql('SELECT COUNT(*) FROM (SELECT DISTINCT EXPLODE(hashtags) FROM TWITTER)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Get top 5 hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('طبق_القدرات_للثانويه_ياريس', 385),\n",
       " ('Corona', 319),\n",
       " ('OilPrice', 251),\n",
       " ('COVID19', 125),\n",
       " ('corona', 123)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD (4 points)\n",
    "rdd_twitter.flatMap(lambda tweet: tweet[2]).map(lambda hashtags: (hashtags, 1)).reduceByKey(lambda a, b: a + b).takeOrdered(5, lambda s: -1 * s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 col|count|\n",
      "+--------------------+-----+\n",
      "|طبق_القدرات_للثان...|  385|\n",
      "|              Corona|  319|\n",
      "|            OilPrice|  251|\n",
      "|             COVID19|  125|\n",
      "|              corona|  123|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using DataFrame (2 points)\n",
    "df_twitter.select(functions.explode(col('hashtags'))).groupby(\"col\").count().sort(\"count\", ascending = False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                 col|count|\n",
      "+--------------------+-----+\n",
      "|طبق_القدرات_للثان...|  385|\n",
      "|              Corona|  319|\n",
      "|            OilPrice|  251|\n",
      "|             COVID19|  125|\n",
      "|              corona|  123|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table. (2 points)\n",
    "spark.sql('SELECT col, COUNT(col) as count FROM (SELECT EXPLODE(hashtags) FROM TWITTER) GROUP BY col ORDER BY count DESC LIMIT 5').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 Get total number of tweets which are retweeted more than 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15753"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "# TODO review: rdd_twitter.filter(lambda tweet: tweet[8] > 100).map(lambda tweet: (tweet[3], 1)).reduceByKey(lambda a, b: a + b).count() gives different value\n",
    "rdd_twitter.filter(lambda tweet: tweet[8] > 100).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15753"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.filter(\"retweet_count > 100\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|count(id)|\n",
      "+---------+\n",
      "|    15753|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "# TODO review: distinct gives different result\n",
    "spark.sql('SELECT COUNT(id) FROM TWITTER WHERE retweet_count > 100').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Get top 3 most retweeted tweets per country (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India',\n",
       "  [['1252332114948874240', 9988],\n",
       "   ['1252252336921206787', 9976],\n",
       "   ['1252254519116746754', 9973]]),\n",
       " ('Pakistan',\n",
       "  [['1252334264248606720', 9988],\n",
       "   ['1252251912084357121', 9975],\n",
       "   ['1252252126694309888', 9973]]),\n",
       " ('USA',\n",
       "  [['1252331777806524416', 9994],\n",
       "   ['1252254239805579264', 9987],\n",
       "   ['1252335464750735362', 9982]]),\n",
       " ('Italy',\n",
       "  [['1252252106750377996', 9994],\n",
       "   ['1252251206027816960', 9984],\n",
       "   ['1252330500670337024', 9971]]),\n",
       " ('Canada',\n",
       "  [['1252335430323888128', 9997],\n",
       "   ['1252254877939531776', 9992],\n",
       "   ['1252252082825986051', 9987]]),\n",
       " ('China',\n",
       "  [['1252335780707684352', 9998],\n",
       "   ['1252253596516843520', 9993],\n",
       "   ['1252255562525560832', 9984]]),\n",
       " ('Chile',\n",
       "  [['1252253612140490759', 9988],\n",
       "   ['1252334891951427585', 9984],\n",
       "   ['1252253710182481920', 9978]]),\n",
       " ('UK',\n",
       "  [['1252333018578145280', 9991],\n",
       "   ['1252252091822870529', 9989],\n",
       "   ['1252254043973603329', 9985]]),\n",
       " ('Mexico',\n",
       "  [['1252253843145912320', 9998],\n",
       "   ['1252255209776189442', 9994],\n",
       "   ['1252252016006422533', 9971]]),\n",
       " ('Spain',\n",
       "  [['1252335445876367361', 9992],\n",
       "   ['1252334839094599681', 9981],\n",
       "   ['1252254696112300032', 9969]]),\n",
       " ('Germany',\n",
       "  [['1252334028092399622', 9999],\n",
       "   ['1252330902325248000', 9997],\n",
       "   ['1252252295510855682', 9990]])]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD\n",
    "from operator import itemgetter\n",
    "\n",
    "rdd_twitter.map(lambda tweet: (tweet[6], [tweet[3], tweet[8]])).groupByKey().mapValues(lambda x: sorted(list(x), key=itemgetter(1), reverse=True)[:3]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-------------+----+\n",
      "|                 id|location|retweet_count|rank|\n",
      "+-------------------+--------+-------------+----+\n",
      "|1252335430323888128|  Canada|         9997|   1|\n",
      "|1252254877939531776|  Canada|         9992|   2|\n",
      "|1252252082825986051|  Canada|         9987|   3|\n",
      "|1252253612140490759|   Chile|         9988|   1|\n",
      "|1252334891951427585|   Chile|         9984|   2|\n",
      "|1252253710182481920|   Chile|         9978|   3|\n",
      "|1252335780707684352|   China|         9998|   1|\n",
      "|1252253596516843520|   China|         9993|   2|\n",
      "|1252255562525560832|   China|         9984|   3|\n",
      "|1252334028092399622| Germany|         9999|   1|\n",
      "|1252330902325248000| Germany|         9997|   2|\n",
      "|1252252295510855682| Germany|         9990|   3|\n",
      "|1252332114948874240|   India|         9988|   1|\n",
      "|1252252336921206787|   India|         9976|   2|\n",
      "|1252254519116746754|   India|         9973|   3|\n",
      "|1252252106750377996|   Italy|         9994|   1|\n",
      "|1252251206027816960|   Italy|         9984|   2|\n",
      "|1252330500670337024|   Italy|         9971|   3|\n",
      "|1252253843145912320|  Mexico|         9998|   1|\n",
      "|1252255209776189442|  Mexico|         9994|   2|\n",
      "+-------------------+--------+-------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank\n",
    "\n",
    "df_twitter.select('id','location','retweet_count', rank().over(Window().partitionBy(\"location\").orderBy(col(\"retweet_count\").desc())).alias('rank')).sort(\"retweet_count\",\n",
    "    ascending=False).filter('rank < 4').sort(\"location\", \"rank\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-------------+\n",
      "|                 id|location|retweet_count|\n",
      "+-------------------+--------+-------------+\n",
      "|1252335430323888128|  Canada|         9997|\n",
      "|1252254877939531776|  Canada|         9992|\n",
      "|1252252082825986051|  Canada|         9987|\n",
      "|1252253612140490759|   Chile|         9988|\n",
      "|1252334891951427585|   Chile|         9984|\n",
      "|1252253710182481920|   Chile|         9978|\n",
      "|1252335780707684352|   China|         9998|\n",
      "|1252253596516843520|   China|         9993|\n",
      "|1252255562525560832|   China|         9984|\n",
      "|1252334028092399622| Germany|         9999|\n",
      "|1252330902325248000| Germany|         9997|\n",
      "|1252252295510855682| Germany|         9990|\n",
      "|1252332114948874240|   India|         9988|\n",
      "|1252252336921206787|   India|         9976|\n",
      "|1252254519116746754|   India|         9973|\n",
      "|1252252106750377996|   Italy|         9994|\n",
      "|1252251206027816960|   Italy|         9984|\n",
      "|1252330500670337024|   Italy|         9971|\n",
      "|1252253843145912320|  Mexico|         9998|\n",
      "|1252255209776189442|  Mexico|         9994|\n",
      "+-------------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "spark.sql('''SELECT id, location, retweet_count FROM (SELECT *, RANK() OVER (PARTITION BY location ORDER BY retweet_count DESC) as rank FROM TWITTER) WHERE rank < 4 ORDER BY location, rank ASC''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9 Total number of tweets per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India', 1480),\n",
       " ('Pakistan', 1470),\n",
       " ('USA', 1539),\n",
       " ('Italy', 1422),\n",
       " ('Canada', 1441),\n",
       " ('China', 1457),\n",
       " ('Chile', 1410),\n",
       " ('UK', 1376),\n",
       " ('Mexico', 1409),\n",
       " ('Spain', 1464),\n",
       " ('Germany', 1426)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RDD (3 points)\n",
    "rdd_twitter.map(lambda tweet: (tweet[6], 1)).reduceByKey(lambda a, b: a + b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|location|count|\n",
      "+--------+-----+\n",
      "| Germany| 1426|\n",
      "|   India| 1480|\n",
      "|   China| 1457|\n",
      "|   Chile| 1410|\n",
      "|   Italy| 1422|\n",
      "|   Spain| 1464|\n",
      "|     USA| 1539|\n",
      "|  Mexico| 1409|\n",
      "|      UK| 1376|\n",
      "|  Canada| 1441|\n",
      "|Pakistan| 1470|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using DataFrame (2 points)\n",
    "df_twitter.groupBy(\"location\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|location|count(id)|\n",
      "+--------+---------+\n",
      "| Germany|     1426|\n",
      "|   India|     1480|\n",
      "|   China|     1457|\n",
      "|   Chile|     1410|\n",
      "|   Italy|     1422|\n",
      "|   Spain|     1464|\n",
      "|     USA|     1539|\n",
      "|  Mexico|     1409|\n",
      "|      UK|     1376|\n",
      "|  Canada|     1441|\n",
      "|Pakistan|     1470|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using spark.sql and the temporay table. (1 point)\n",
    "spark.sql('SELECT location, COUNT(id) FROM TWITTER GROUP BY location').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 save the data such that you have seperate folder per country (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.withColumn(\"hashtags\", col(\"hashtags\").cast(\"string\")).write.partitionBy('location').csv(\"location\", header = 'true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Save the data as parquet files (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame\n",
    "df_twitter.write.partitionBy('location').parquet(\"location.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
