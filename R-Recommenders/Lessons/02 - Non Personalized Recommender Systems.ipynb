{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>Updated February 2022 - This notebook was created by [Santi Segu√≠](https://ssegui.github.io/). </i></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loren\\AppData\\Local\\Temp\\ipykernel_14836\\3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Non-Personalized recommeder systems</h3><br></div>\n",
    "\n",
    "<br>\n",
    "<p>A non-personalized recommender system is one that makes the same recommendations for everyone. </p>\n",
    "\n",
    "The simplest example is a retailer that shows the ten (or some number) most popular products on their homepage. <br>\n",
    "Some examples: <br><br>\n",
    "IMDB: MOVIE RANKING\n",
    "![alt IMDB](images/np1.png)\n",
    "\n",
    "___\n",
    "Amazon: Top Recommendations\n",
    "![alt Amazon](images/np2.png)\n",
    "___\n",
    "Amazon: Product Association\n",
    "![alt Amazon](images/np3.png)\n",
    "___\n",
    "Reedit: News Recommendations\n",
    "![alt Reedit](images/np4.png)\n",
    "\n",
    "\n",
    "<p><b>Several</b> cases but <b>two main</b> approaches\n",
    "\n",
    "1. Aggregated opinion recommenders\n",
    "2. Basic product association recommenders\n",
    "<br>\n",
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Aggregated opinion recommenders</h3><br></div>\n",
    "\n",
    "Usually, the problem posed as a learning to rank problem. But what seems to be straighfowrard becomes a really complicated question: <b>How do you rank your rated items and which logic to use to display them?</b>\n",
    "\n",
    "In order to score/rank items we first have to <b>understand the business case</b>. Of course, several factors plays a role. For instance, \n",
    "\n",
    "* Which information do we have about the items? Bought / Seen / Rated / ... \n",
    "* From how many users do we have the info for a particular item \n",
    "* How old is that info? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE: Non-Personalised Recommender using MovieLens Dataset\n",
    "We will work with the well known MovieLens dataset (http://grouplens.org/datasets/movielens/). This dataset was initially constructed to support participants in the Netflix Prize. Today, we can find several versions of this dataset with different amout of data, from 100k samples version to 20m sample version. Although performance on bigger dataset is expected to be better, we will work with the smallest dataset: MovieLens 100K Dataset (ml-100k-zip). Working with this lite version has the benefit of less computational costs\n",
    "\n",
    "With a unix machine the dataset can be downloaded with the following code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n",
      "\"unzip\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip \n",
    "!unzip ml-1m.zip -d \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with a windows machine, please go to the website and download the ml-1m version and extract it to the subdirectory named \"data/ml-1m/\"\n",
    "\n",
    "Once you have downloaded and unzipped the file into a directory, you can create a DataFrame with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(150000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-f75c43d64d91>:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users = pd.read_csv('./data/ml-1m/users.dat', sep='::', names=u_cols)\n",
      "<ipython-input-7-f75c43d64d91>:14: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings = pd.read_csv('./data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
      "<ipython-input-7-f75c43d64d91>:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies = pd.read_csv('./data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La BD has 1000209 ratings\n",
      "La BD has  6040  users\n",
      "La BD has  3706  movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                   title  movie_id  rating  \\\n",
       "0        1  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "1        2  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "2       12  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
       "3       15  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
       "4       17  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "\n",
       "  release_date sex  age  \n",
       "0        Drama   F    1  \n",
       "1        Drama   M   56  \n",
       "2        Drama   M   25  \n",
       "3        Drama   M   25  \n",
       "4        Drama   M   50  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NETFLIX REAL 50.000.000 usuaris and 100.000 items\n",
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Load Data set\n",
    "u_cols = ['user_id', 'sex', 'age', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./data/ml-1m/users.dat', sep='::', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('./data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first three columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date',]\n",
    "movies = pd.read_csv('./data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "# Construcci√≥ del DataFrame\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "print(\"La BD has \"+ str(data.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", data.user_id.nunique(),\" users\")\n",
    "print(\"La BD has \", data.movie_id.nunique(), \" movies\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you explore the dataset in detail, you will see that it consists of:\n",
    "\n",
    "100,000 ratings from 943 users of 1682 movies. Ratings are from 1 to 5.\n",
    "Each user has rated at least 20 movies.\n",
    "Simple demographic info for the users (age, gender, occupation, zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Top movies ranking. \n",
    "The simplest way to show the ranking is by using the mean rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ulysses (Ulisse) (1954)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lured (1947)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Follow the Bitch (1998)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bittersweet Motel (2000)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Song of Freedom (1936)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One Little Indian (1973)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smashing Time (1967)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schlafes Bruder (Brother of Sleep) (1995)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gate of Heavenly Peace, The (1995)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baby, The (1973)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           mean_rating\n",
       "title                                                 \n",
       "Ulysses (Ulisse) (1954)                            5.0\n",
       "Lured (1947)                                       5.0\n",
       "Follow the Bitch (1998)                            5.0\n",
       "Bittersweet Motel (2000)                           5.0\n",
       "Song of Freedom (1936)                             5.0\n",
       "One Little Indian (1973)                           5.0\n",
       "Smashing Time (1967)                               5.0\n",
       "Schlafes Bruder (Brother of Sleep) (1995)          5.0\n",
       "Gate of Heavenly Peace, The (1995)                 5.0\n",
       "Baby, The (1973)                                   5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score = data.groupby(['title'])[['rating']].mean().rename(columns = {'rating': 'mean_rating'})\n",
    "mean_score.sort_values(by='mean_rating',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "**What do you think about the output?**\n",
    "\n",
    "Now, let's show only ranking the mean rating but using only those movies with at least 20 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Shawshank Redemption, The (1994)</th>\n",
       "      <td>4.554558</td>\n",
       "      <td>2227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Godfather, The (1972)</th>\n",
       "      <td>4.524966</td>\n",
       "      <td>2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usual Suspects, The (1995)</th>\n",
       "      <td>4.517106</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schindler's List (1993)</th>\n",
       "      <td>4.510417</td>\n",
       "      <td>2304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raiders of the Lost Ark (1981)</th>\n",
       "      <td>4.477725</td>\n",
       "      <td>2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rear Window (1954)</th>\n",
       "      <td>4.476190</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Wars: Episode IV - A New Hope (1977)</th>\n",
       "      <td>4.453694</td>\n",
       "      <td>2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)</th>\n",
       "      <td>4.449890</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Casablanca (1942)</th>\n",
       "      <td>4.412822</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sixth Sense, The (1999)</th>\n",
       "      <td>4.406263</td>\n",
       "      <td>2459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_rating  num_ratings\n",
       "title                                                                       \n",
       "Shawshank Redemption, The (1994)                       4.554558         2227\n",
       "Godfather, The (1972)                                  4.524966         2223\n",
       "Usual Suspects, The (1995)                             4.517106         1783\n",
       "Schindler's List (1993)                                4.510417         2304\n",
       "Raiders of the Lost Ark (1981)                         4.477725         2514\n",
       "Rear Window (1954)                                     4.476190         1050\n",
       "Star Wars: Episode IV - A New Hope (1977)              4.453694         2991\n",
       "Dr. Strangelove or: How I Learned to Stop Worry...     4.449890         1367\n",
       "Casablanca (1942)                                      4.412822         1669\n",
       "Sixth Sense, The (1999)                                4.406263         2459"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score = data.groupby(['title'])[['rating','title']].agg({'rating':'mean',\n",
    "                                                              'title':'count'}).rename(columns = {'rating': 'mean_rating','title':'num_ratings'})\n",
    "mean_score[mean_score['num_ratings']>1000].sort_values(by='mean_rating',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "**Any other idea?**\n",
    "\n",
    "How can you improve it?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "mean_rating = data.rating.mean()\n",
    "mean_score['damped_mean'] = (mean_score['mean_rating']*mean_score['num_ratings'] + k*mean_rating) / (k + mean_score['num_ratings']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>damped_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Shawshank Redemption, The (1994)</th>\n",
       "      <td>4.554558</td>\n",
       "      <td>2227</td>\n",
       "      <td>4.550208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)</th>\n",
       "      <td>4.560510</td>\n",
       "      <td>628</td>\n",
       "      <td>4.545166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Godfather, The (1972)</th>\n",
       "      <td>4.524966</td>\n",
       "      <td>2223</td>\n",
       "      <td>4.520741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usual Suspects, The (1995)</th>\n",
       "      <td>4.517106</td>\n",
       "      <td>1783</td>\n",
       "      <td>4.511888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close Shave, A (1995)</th>\n",
       "      <td>4.520548</td>\n",
       "      <td>657</td>\n",
       "      <td>4.506470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schindler's List (1993)</th>\n",
       "      <td>4.510417</td>\n",
       "      <td>2304</td>\n",
       "      <td>4.506403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wrong Trousers, The (1993)</th>\n",
       "      <td>4.507937</td>\n",
       "      <td>882</td>\n",
       "      <td>4.497551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sanjuro (1962)</th>\n",
       "      <td>4.608696</td>\n",
       "      <td>69</td>\n",
       "      <td>4.478679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raiders of the Lost Ark (1981)</th>\n",
       "      <td>4.477725</td>\n",
       "      <td>2514</td>\n",
       "      <td>4.474174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)</th>\n",
       "      <td>4.491489</td>\n",
       "      <td>470</td>\n",
       "      <td>4.472533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_rating  num_ratings  \\\n",
       "title                                                                          \n",
       "Shawshank Redemption, The (1994)                       4.554558         2227   \n",
       "Seven Samurai (The Magnificent Seven) (Shichini...     4.560510          628   \n",
       "Godfather, The (1972)                                  4.524966         2223   \n",
       "Usual Suspects, The (1995)                             4.517106         1783   \n",
       "Close Shave, A (1995)                                  4.520548          657   \n",
       "Schindler's List (1993)                                4.510417         2304   \n",
       "Wrong Trousers, The (1993)                             4.507937          882   \n",
       "Sanjuro (1962)                                         4.608696           69   \n",
       "Raiders of the Lost Ark (1981)                         4.477725         2514   \n",
       "Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)          4.491489          470   \n",
       "\n",
       "                                                    damped_mean  \n",
       "title                                                            \n",
       "Shawshank Redemption, The (1994)                       4.550208  \n",
       "Seven Samurai (The Magnificent Seven) (Shichini...     4.545166  \n",
       "Godfather, The (1972)                                  4.520741  \n",
       "Usual Suspects, The (1995)                             4.511888  \n",
       "Close Shave, A (1995)                                  4.506470  \n",
       "Schindler's List (1993)                                4.506403  \n",
       "Wrong Trousers, The (1993)                             4.497551  \n",
       "Sanjuro (1962)                                         4.478679  \n",
       "Raiders of the Lost Ark (1981)                         4.474174  \n",
       "Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)          4.472533  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score.sort_values(by='damped_mean', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Basic product association recommenders\n",
    "</h3><br> People who buy X also buy Y. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different items 171\n",
      "Number of rows  9835\n",
      "An example: ['pip fruit', 'yogurt', 'cream cheese ', 'meat spreads']\n"
     ]
    }
   ],
   "source": [
    "#Let's read a dataset which contains several market baskets lists\n",
    "\n",
    "# read data/grocieries.csv\n",
    "def union(a, b):\n",
    "    \"\"\" return the union of two lists \"\"\"\n",
    "    return list(set(a) | set(b))\n",
    "\n",
    "market_data = []\n",
    "cont = 0\n",
    "items = []\n",
    "with open(\"./data/groceries.csv\") as f:\n",
    "    for l in f:\n",
    "        market_data.append(l.rstrip().split(','))\n",
    "        items = union(items,l.rstrip().split(','))\n",
    "\n",
    "print(\"Number of different items\", len(items))\n",
    "print(\"Number of rows \", len(market_data))\n",
    "\n",
    "\n",
    "print(\"An example:\", market_data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most simple ways to found association between product could be obtained as follows: $$score(Y|X) = \\frac{X \\ and \\ Y}{X}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which is the top associated product with \"yogurt\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_associated_products(product,N = 5):\n",
    "    d = {}\n",
    "    times = 0\n",
    "    for l in market_data:\n",
    "        if product in l:\n",
    "            times = times + 1\n",
    "            for i in l:\n",
    "                if i != product: \n",
    "                    if(i in d):\n",
    "                        d[i] += 1.0\n",
    "                    else:\n",
    "                        d[i] = 1.0\n",
    "\n",
    "    for k in d:\n",
    "        d[k] =   d[k] / times\n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.40160349854227406), ('other vegetables', 0.3112244897959184), ('rolls/buns', 0.24635568513119532)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.6133333333333333), ('other vegetables', 0.52), ('root vegetables', 0.41333333333333333)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.38636363636363635), ('other vegetables', 0.3409090909090909), ('tropical fruit', 0.20454545454545456)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rum\"?\n",
    "s = top_associated_products('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "What happens? Is it a good measure? It has a problem with popular items...\n",
    "<br>\n",
    "Let's check this other formula:\n",
    "$$score(Y|X) = \\frac{ \\frac{X \\ and \\ Y}{X}} {  \\frac{!X \\ and \\ Y}{!X} }  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def top_associated_products2(product,N = 5):\n",
    "    d = {}\n",
    "    times = 0\n",
    "    for l in market_data:\n",
    "        if product in l:\n",
    "            times = times + 1\n",
    "            for i in l:\n",
    "                if i != product: \n",
    "                    if(i in d):\n",
    "                        d[i] += 1.0\n",
    "                    else:\n",
    "                        d[i] = 1.0\n",
    "\n",
    "    for k in d:\n",
    "        d[k] =   d[k] / times\n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.40160349854227406), ('other vegetables', 0.3112244897959184), ('rolls/buns', 0.24635568513119532)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products2('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.6133333333333333), ('other vegetables', 0.52), ('root vegetables', 0.41333333333333333)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products2('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.38636363636363635), ('other vegetables', 0.3409090909090909), ('tropical fruit', 0.20454545454545456)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rum\"?\n",
    "s = top_associated_products2('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check this last formula:\n",
    "$$ score(Y|X) = \\frac{P(X \\ and \\ Y)}{P(X)P(Y) }   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_associated_products3(product,N = 5):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products3('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products3('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products3('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products3('baby food',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APRIORI Algorithm\n",
    "Typically, association rules are considered interesting if they satisfy both a minimum support threshold and a minimum confidence threshold\n",
    "\n",
    "![alt apriori](images/apriori.png)\n",
    "\n",
    "<b>Apriori principle</b>: Any subset of a frequent itemset must be frequent\n",
    "\n",
    "> Step 1: Find the frequent itemsset: the set of items that have minimum support.\n",
    "> -  A subset of a frequent itemset must also be a frequent itemset  i.e. if {1,2} is a frequent itemset, both {1} and {2} should be a frequent itemset\n",
    "> - Iteratively find frequent itemsets with cardinality from 1 to k (k-itemset)\n",
    "\n",
    "> Step 2: Use the frequent itemsets to generate association rules\n",
    "\n",
    "![alt apriori2](images/apriori2.png)\n",
    "\n",
    "Reference : \n",
    "[Fast algorithms for mining association rules](http://www-cgi.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ngm/15-721/summaries/12.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted code from https://github.com/asaini/Apriori\n",
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "\n",
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])\n",
    "\n",
    "\n",
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "        \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "       of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "        _itemSet = set()\n",
    "        localSet = defaultdict(int)\n",
    "\n",
    "        for item in itemSet:\n",
    "                for transaction in transactionList:\n",
    "                        if item.issubset(transaction):\n",
    "                                freqSet[item] += 1\n",
    "                                localSet[item] += 1\n",
    "\n",
    "        for item, count in localSet.items():\n",
    "                support = float(count)/len(transactionList)\n",
    "\n",
    "                if support >= minSupport:\n",
    "                        _itemSet.add(item)\n",
    "\n",
    "        return _itemSet\n",
    "\n",
    "\n",
    "def joinSet(itemSet, length):\n",
    "        \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "        return set([i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length])\n",
    "\n",
    "\n",
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))              # Generate 1-itemSets\n",
    "    return itemSet, transactionList\n",
    "\n",
    "\n",
    "def runApriori(data_iter, minSupport, minConfidence):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    \n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "    \n",
    "    oneCSet = returnItemsWithMinSupport(itemSet,\n",
    "                                        transactionList,\n",
    "                                        minSupport,\n",
    "                                        freqSet)\n",
    "\n",
    "    \n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while(currentLSet != set([])):\n",
    "        largeSet[k-1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(currentLSet,\n",
    "                                                transactionList,\n",
    "                                                minSupport,\n",
    "                                                freqSet)\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "\n",
    "    def getSupport(item):\n",
    "            \"\"\"local function which Returns the support of an item\"\"\"\n",
    "            return float(freqSet[item])/len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in list(largeSet.items()):\n",
    "        toRetItems.extend([(tuple(item), getSupport(item))\n",
    "                           for item in value])\n",
    "\n",
    "    toRetRules = []\n",
    "    for key, value in list(largeSet.items())[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence = getSupport(item)/getSupport(element)\n",
    "                    if confidence >= minConfidence:\n",
    "                        toRetRules.append(((tuple(element), tuple(remain)),\n",
    "                                           confidence))\n",
    "    return toRetItems, toRetRules\n",
    "\n",
    "\n",
    "def printResults(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    for item, support in sorted(items, key = lambda x: float(x[1])):\n",
    "        print(\"item: %s , %.3f\" % (str(item), support))\n",
    "    print(\"\\n------------------------ RULES:\")\n",
    "    for rule, confidence in sorted(rules, key=lambda x: float(x[1])):\n",
    "        pre, post = rule\n",
    "        print(\"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence))\n",
    "\n",
    "\n",
    "def dataFromFile(fname):\n",
    "        \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "        file_iter = open(fname, 'r')\n",
    "        for line in file_iter:\n",
    "                line = line.strip().rstrip(',')                         # Remove trailing comma\n",
    "                record = frozenset(line.split(','))\n",
    "                yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: ('soda', 'whole milk') , 0.040\n",
      "item: ('white bread',) , 0.042\n",
      "item: ('tropical fruit', 'whole milk') , 0.042\n",
      "item: ('rolls/buns', 'other vegetables') , 0.043\n",
      "item: ('chicken',) , 0.043\n",
      "item: ('other vegetables', 'yogurt') , 0.043\n",
      "item: ('other vegetables', 'root vegetables') , 0.047\n",
      "item: ('frozen vegetables',) , 0.048\n",
      "item: ('root vegetables', 'whole milk') , 0.049\n",
      "item: ('chocolate',) , 0.050\n",
      "item: ('napkins',) , 0.052\n",
      "item: ('beef',) , 0.052\n",
      "item: ('curd',) , 0.053\n",
      "item: ('butter',) , 0.055\n",
      "item: ('whole milk', 'yogurt') , 0.056\n",
      "item: ('rolls/buns', 'whole milk') , 0.057\n",
      "item: ('pork',) , 0.058\n",
      "item: ('coffee',) , 0.058\n",
      "item: ('margarine',) , 0.059\n",
      "item: ('frankfurter',) , 0.059\n",
      "item: ('domestic eggs',) , 0.063\n",
      "item: ('brown bread',) , 0.065\n",
      "item: ('whipped/sour cream',) , 0.072\n",
      "item: ('fruit/vegetable juice',) , 0.072\n",
      "item: ('other vegetables', 'whole milk') , 0.075\n",
      "item: ('pip fruit',) , 0.076\n",
      "item: ('canned beer',) , 0.078\n",
      "item: ('newspapers',) , 0.080\n",
      "item: ('bottled beer',) , 0.081\n",
      "item: ('citrus fruit',) , 0.083\n",
      "item: ('pastry',) , 0.089\n",
      "item: ('sausage',) , 0.094\n",
      "item: ('shopping bags',) , 0.099\n",
      "item: ('tropical fruit',) , 0.105\n",
      "item: ('root vegetables',) , 0.109\n",
      "item: ('bottled water',) , 0.111\n",
      "item: ('yogurt',) , 0.140\n",
      "item: ('soda',) , 0.174\n",
      "item: ('rolls/buns',) , 0.184\n",
      "item: ('other vegetables',) , 0.193\n",
      "item: ('whole milk',) , 0.256\n",
      "\n",
      "------------------------ RULES:\n",
      "Rule: ('whole milk',) ==> ('yogurt',) , 0.219\n",
      "Rule: ('other vegetables',) ==> ('rolls/buns',) , 0.220\n",
      "Rule: ('whole milk',) ==> ('rolls/buns',) , 0.222\n",
      "Rule: ('other vegetables',) ==> ('yogurt',) , 0.224\n",
      "Rule: ('soda',) ==> ('whole milk',) , 0.230\n",
      "Rule: ('rolls/buns',) ==> ('other vegetables',) , 0.232\n",
      "Rule: ('other vegetables',) ==> ('root vegetables',) , 0.245\n",
      "Rule: ('whole milk',) ==> ('other vegetables',) , 0.293\n",
      "Rule: ('rolls/buns',) ==> ('whole milk',) , 0.308\n",
      "Rule: ('yogurt',) ==> ('other vegetables',) , 0.311\n",
      "Rule: ('other vegetables',) ==> ('whole milk',) , 0.387\n",
      "Rule: ('yogurt',) ==> ('whole milk',) , 0.402\n",
      "Rule: ('tropical fruit',) ==> ('whole milk',) , 0.403\n",
      "Rule: ('root vegetables',) ==> ('other vegetables',) , 0.435\n",
      "Rule: ('root vegetables',) ==> ('whole milk',) , 0.449\n"
     ]
    }
   ],
   "source": [
    "inFile = dataFromFile('./data/groceries.csv')\n",
    "minSupport = 0.04\n",
    "minConfidence = 0.2\n",
    "items, rules =  runApriori(inFile, minSupport, minConfidence)\n",
    "printResults(items, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class  = \"alert alert-success\"><b>Exercice: Create and Product Association Recommender with MovieLens Dataset</b><p>\n",
    "Explain the obtained results and conclusions.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
