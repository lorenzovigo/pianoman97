{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Inference\n",
    "\n",
    "In this notebook you will understand the steps of the algorithm of Variable Elimination (Sum-Product) for computing marginal probability distributions. We will use <b>pgmpy</b> for the construction of the model.\n",
    "\n",
    "First of all, we need to import the necessary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD, DiscreteFactor\n",
    "\n",
    "from pgmpy.inference import VariableElimination, BeliefPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up our model\n",
    "\n",
    "We will use the classical (enlarged) students example, which has the following graph structure:\n",
    "\n",
    "<img src=\"images/students_bn.png\" style=\"width:200px\" />\n",
    "\n",
    "We need to codify the graph structure and the Conditional Probability Distribution families\n",
    "\n",
    "### Set the structure\n",
    "\n",
    "First of all, we need to specify that we are constructing a Bayesian network and the set of directed edges as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = ['C', 'D', 'I', 'G', 'S', 'L', 'J', 'H']\n",
    "G = BayesianModel([('D', 'G'), ('I', 'G'), ('I', 'S'), ('G', 'L'),\n",
    "                  ('C','D'), ('G','H'), ('J','H'), ('S','J'), ('L','J')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Conditional Probability Distribution families\n",
    "\n",
    "Once the structure has been defined, we codify the respective CPDs as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cpd = TabularCPD('C', 2, [[0.2], [0.8]])\n",
    "d_cpd = TabularCPD('D', 2, [[0.3, 0.4], \n",
    "                            [0.7, 0.6]],\n",
    "                   evidence=['C'], evidence_card=[2])\n",
    "i_cpd = TabularCPD('I', 3, [[0.5], [0.3], [0.2]])\n",
    "g_cpd = TabularCPD('G', 3, [[0.1, 0.2, 0.1, 0.1, 0.2, 0.3],\n",
    "                            [0.1, 0.3, 0.3, 0.2, 0.2, 0.3],\n",
    "                            [0.8, 0.5, 0.6, 0.7, 0.6, 0.4]],\n",
    "                   evidence=['D', 'I'], evidence_card=[2, 3])\n",
    "s_cpd = TabularCPD('S', 2, [[0.1, 0.2, 0.7],\n",
    "                            [0.9, 0.8, 0.3]],\n",
    "                   evidence=['I'], evidence_card=[3])\n",
    "l_cpd = TabularCPD('L', 2, [[0.1, 0.4, 0.8],\n",
    "                            [0.9, 0.6, 0.2]],\n",
    "                   evidence=['G'], evidence_card=[3])\n",
    "j_cpd = TabularCPD('J', 2, [[0.1, 0.5, 0.4, 0.6],\n",
    "                            [0.9, 0.5, 0.6, 0.4]],\n",
    "                   evidence=['L', 'S'], evidence_card=[2, 2])\n",
    "h_cpd = TabularCPD('H', 3, [[0.7, 0.3, 0.5, 0.3, 0.2, 0.4],\n",
    "                            [0.1, 0.3, 0.4, 0.4, 0.6, 0.3],\n",
    "                            [0.2, 0.4, 0.1, 0.3, 0.2, 0.3]],\n",
    "                   evidence=['G', 'J'], evidence_card=[3, 2])\n",
    "\n",
    "G.add_cpds(c_cpd, d_cpd, i_cpd, g_cpd, s_cpd, l_cpd, j_cpd, h_cpd)\n",
    "print('Is the model right?',G.check_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Elimination\n",
    "\n",
    "The library <b>pgmpy</b> implements the algorithm, so let us use it to work a few concepts that we have studied in the theory lessons.\n",
    "\n",
    "First of all, we need to tell the library that we want to use Variable Elimination over the graph $\\mathcal{G}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = VariableElimination(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we explained, the induced graph is an undirected graph that we produce as we execute VE. The width of the induced graph is defined as the number of variables in the largest clique of the induced graph minus one.\n",
    "\n",
    "The width of the induced graph determines the time complexity of the VE algorithm. Remember that it is exponential in this width. However, the induced graph that we end up with (and, therefore, its width) depends on the elimination ordering followed.\n",
    "\n",
    "Let us compute the width of the induced graph for the different possible orderings of the variables using pgmpy's `induced_width` (let's go for a coffee, this might take its time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indwidth = {}\n",
    "\n",
    "for perm in it.permutations(nodes):\n",
    "    indwidth.update({perm: inference.induced_width(perm)})\n",
    "\n",
    "print('The lowest induced width is:', np.min(list(indwidth.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that that width is achieved by several orderings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Induced width of all the\",len(list(indwidth.values())),\"possible orderings\")\n",
    "print(\"Number of orderings with width=3:\",len(np.where(np.array(list(indwidth.values()))==3)[0]))\n",
    "print(\"Width of all the orderings:\")\n",
    "print(list(indwidth.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Three examples of orderings with the minimum induced width (3):\")\n",
    "bOrd = np.argsort(list(indwidth.values()))[:3]\n",
    "for i in bOrd:\n",
    "    print(list(indwidth.keys())[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let us see a few examples in detail:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = {'C': (0, 0), 'D': (0, -2), 'I': (2, -2), 'G': (1, -3), 'S': (3, -3), \n",
    "       'L': (1, -4), 'J': (2, -5), 'H': (0, -6)} \n",
    "\n",
    "orden = list(indwidth.keys())[bOrd[2]]\n",
    "print(\"- The ordering\",orden,\"produces the following graph:\") \n",
    "ig = inference.induced_graph(orden)\n",
    "nx.draw(ig, with_labels=True, pos=pos, font_weight='bold',node_color='#cccccc', node_size=1000)\n",
    "plt.show()\n",
    "print(\"   + this graph has induced width:\",inference.induced_width(orden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orden = ('C', 'D', 'I', 'H', 'J', 'L', 'S', 'G')\n",
    "print(\"\\n- One of the most obvious orderings\",orden,\"produces the following graph:\")\n",
    "ig = inference.induced_graph(orden)\n",
    "nx.draw(ig, with_labels=True, pos=pos, font_weight='bold',node_color='#cccccc', node_size=1000)\n",
    "plt.show()\n",
    "print(\"   + this graph has induced width:\",inference.induced_width(orden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Two different orderings produce the same induced graph, with width=3. Note, however, that different induced graphs might show the same width too, as only the maximum clique is considered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orden = ('G', 'D', 'C', 'I', 'S', 'L', 'H', 'J')\n",
    "print(\"\\n- A bad ordering\",orden,\"produces the following graph:\")\n",
    "ig = inference.induced_graph(orden)\n",
    "nx.draw(ig, with_labels=True, pos=pos, font_weight='bold',node_color='#cccccc', node_size=1000)\n",
    "plt.show()\n",
    "print(\"   + this graph has induced width:\",inference.induced_width(orden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The last example is a bad ordering decision as the first variable to eliminate is the most densely connected.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "## Operations of VE sum-product\n",
    "There are two main operations in the Sum-Product VE algorithm: Marginalization (Sum) and Product.\n",
    "\n",
    "Let us have a look to the use of the <b>Marginalization</b> operation. First of all, in VE we work with undirected graphs. Thus, we have to convert CPDs to factors. Factors in pgmpy already include the function of marginalization, which takes as parameter the list of variables to marginalize out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_j = G.get_cpds('J').to_factor()\n",
    "print(\"The CPD of J|L,S converted to a factor:\")\n",
    "print(phi_j)\n",
    "\n",
    "phi_j.marginalize(['S'])\n",
    "print(\"The factor over J,L,S after marginalizing out the variable S:\")\n",
    "print(phi_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let us have a look to the use of the <b>Product</b> operation. This is also a function of the factor in pgmpy. It just takes as parameter another factor to multiply with. The product of factor $\\phi_b(L,S)$ and $\\phi_a(J,L)$ (the result of the previous marginalization):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_l = G.get_cpds('L').to_factor()\n",
    "print(phi_l)\n",
    "print(phi_j)\n",
    "\n",
    "phi_l.product(phi_j)\n",
    "print(\"Product of factors:\")\n",
    "print(phi_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we are familiar in <b>pgmpy</b> with the two necessary operations for VE, let us compute the following marginal:\n",
    "$$p(L)=\\sum_{\\mathbf{x}}p(\\mathbf{x})$$\n",
    "\n",
    "To do so, first of all we have to provide an ordering. Let us use the following: $[C,D,I,H,J,S,G]$.\n",
    "\n",
    "$$p(L) = \\sum_g p(l|g) \\sum_s \\sum_j p(j|s,l) \\sum_h p(h|g,j) \\sum_i p(i)p(s|i)\\sum_d p(g|d,i)\\sum_c p(d|c)p(c)$$\n",
    "\n",
    "The first step is, therefore, to marginalize out $C$. To do so, we need the product of all the factors that include $C$ previous to marginalize out $C$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau1 = G.get_cpds('C').to_factor()\n",
    "print(\"Involved factors:\")\n",
    "print(tau1)\n",
    "print(G.get_cpds('D').to_factor())\n",
    "\n",
    "tau1.product(G.get_cpds('D').to_factor())\n",
    "print(\"Product of involved factors:\")\n",
    "print(tau1)\n",
    "tau1.marginalize(['C'])\n",
    "print(\"C is marginalized out from the previous factor:\")\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following step is to marginalize out $D$. It is necessary to carry out the product of all the involved factors: the CPD of $G|D,I$ and the result of the previous marginalization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Factor of G (involves D):\")\n",
    "########################\n",
    "#### YOUR CODE HERE ####\n",
    "########################\n",
    "print(\"D is marginalized out from the product of the two previous factors:\")\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To marginalize out $I$, there are three involved factors: the marginal of $I$, the CPD of $S|I$ and the previously marginalized factor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Involved factors:\")\n",
    "########################\n",
    "#### YOUR CODE HERE ####\n",
    "########################\n",
    "print(\"I is marginalized out from the product of the three previous factors:\")\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the following case, $H$ is only involved in one factor, so no product is required. The operation is limited to a marginalization step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Involved factor:\")\n",
    "print(G.get_cpds('H').to_factor())\n",
    "tau2 = G.get_cpds('H').to_factor()\n",
    "tau2.marginalize(['H'])\n",
    "print(\"H is marginalized out from the previous factor:\")\n",
    "print(tau2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that we have now two induced factors, $\\tau_1$ and $\\tau_2$.\n",
    "\n",
    "The following marginalization, that of $J$ is only related with factor $\\tau_2$ and the CPD of $J|L,S$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Involved factor:\")\n",
    "print(G.get_cpds('J').to_factor())\n",
    "tau2.product(G.get_cpds('J').to_factor())\n",
    "tau2.marginalize(['J'])\n",
    "print(\"J is marginalized out from the product of the two previous factors:\")\n",
    "print(tau2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To marginalize out $S$ we combine (product) both induced factors, $\\tau_1$ and $\\tau_2$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau1.product(tau2)\n",
    "tau1.marginalize(['S'])\n",
    "print(\"S is marginalized out from the product of the two previously induced factors:\")\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "At this point, only two variables remain in the model: $G$ and $L$. To marginalize out, we have to combine (product) the previous induced factor and the CPD of $L|G$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Involved factor:\")\n",
    "tau1.product(G.get_cpds('L').to_factor())\n",
    "tau1.marginalize(['G'])\n",
    "print(\"G is marginalized out from the product of the two previous factors:\")\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Thus, we obtain the marginal probability distribution of $L$ (note that our factors are in fact CPDs, so no normalization is required), the query that we posed above.\n",
    "\n",
    "Let us compare our result with that of the implemented function of <b>pgmpy<b/>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_query = inference.query(['L'])\n",
    "print(phi_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "Exercises:\n",
    "\n",
    "- Try $p(S)$\n",
    "\n",
    "- Try $p(J)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with evidence\n",
    "\n",
    "If we want to carry out queries where some evidence about a subset of variables is available, we need to consider a third operation: Reduction.\n",
    "\n",
    "Let us have a look to the use of the <b>Reduction</b> operation. Factors in pgmpy already include the function of marginalization, which takes as parameter the list of pairs (variable-value) for the reduction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_j = G.get_cpds('J').to_factor()\n",
    "print(\"The CPD of J|L,S converted to a factor:\")\n",
    "print(phi_j)\n",
    "\n",
    "phi_j.reduce([('S', 0)])\n",
    "print(\"The factor over J,L,S after reducing the variable S with value 0:\")\n",
    "print(phi_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we are familiar in <b>pgmpy</b> with the three necessary operations, let us compute the following marginal:\n",
    "$$p(L|C=0,J=0)=\\frac{1}{\\Theta}\\sum_{g,s,h,i,d}p(G=g,S=s,H=h,I=i,D=d,C=0,J=0)$$\n",
    "\n",
    "To do so, first of all we have to provide an ordering. Let us use the following: $[D,I,H,S,G]$.\n",
    "\n",
    "$$p(L|C=0,J=0) = \\sum_g p(l|g) \\sum_s p(J=0|s,l) \\sum_h p(h|g,J=0) \\sum_i p(i)p(s|i)\\sum_d p(g|d,i) p(d|C=0)p(C=0)$$\n",
    "\n",
    "The first step is, therefore, to reduce $C$ from the factors that include it.  After the reduction of both involved factors, we can obtain the product of these temporary factors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau1 = \n",
    "\n",
    "########################\n",
    "#### YOUR CODE HERE ####\n",
    "########################\n",
    "\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The first marginalization, in this case, is that of $D$. As before, we need to combine (product) the previous resulting factor over D and the CPD of $G|D,I$ and marginalize out $D$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau1.product(G.get_cpds('G').to_factor())\n",
    "tau1.marginalize(['D'])\n",
    "print(\"The product of the previous factor and that over G,D,I after marginalization of D:\")\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The marginalization of $I$ is exactly as before:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau1.product(G.get_cpds('I').to_factor())\n",
    "tau1.product(G.get_cpds('S').to_factor())\n",
    "tau1.marginalize(['I'])\n",
    "print(\"The product of the previous factor, that over S,I and the marginal of I after marginalization of I:\")\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The marginalization of $H$ and $J$, however, are preceded by the reduction of $J=0$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau2 = G.get_cpds('H').to_factor()\n",
    "tau2.reduce([('J', 0)])\n",
    "tau2.marginalize(['H'])\n",
    "print(\"The marginalization of H,J,G after reduction of J=0:\")\n",
    "print(tau2)\n",
    "\n",
    "aux = G.get_cpds('J').to_factor()\n",
    "aux.reduce([('J', 0)])\n",
    "tau2.product(aux)\n",
    "print(\"The product of the previous factor and that of J,G,S after reduction of J=0:\")\n",
    "print(tau2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, $S$ and $G$ are marginalized out exactly as before. Note, however, that in this case normalization is required due to reduction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau1.product(tau2)\n",
    "tau1.marginalize(['S'])\n",
    "\n",
    "tau1.product(G.get_cpds('L').to_factor())\n",
    "tau1.marginalize(['G'])\n",
    "print(\"G is marginalized out from the product of the two previous factors:\")\n",
    "print(tau1)\n",
    "tau1.normalize()\n",
    "print(\"And, after normalization:\")\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Thus, we obtain the marginal probability distribution of $L$ given $C=0$ and $J=0$, the query that we posed above.\n",
    "\n",
    "Let us compare our result with that of the implemented function of <b>pgmpy<b/>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_query = inference.query(['L'], evidence = {'C': 0, 'J': 0})\n",
    "print(phi_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "Exercises:\n",
    "\n",
    "- Try $p(S|D=1,J=1)$\n",
    "\n",
    "\n",
    "- Try $p(J|H=1,G=1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "## MAP inference: max-sum VE\n",
    "\n",
    "Sometimes, we want to calculate the assignment of values that maximizes the marginal, that is, MAP inference. This  is carried out by the max-sum version of variable elimination, which considers the operations of max-marginalization and sum of factors. The function in <b>pgmpy</b> for the query\n",
    "$$\\arg\\max_{g,i} p(G=g,I=i)$$\n",
    "is: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAP query, argmax_{g,i} P(G=g, I=i):')\n",
    "print(inference.map_query(['G', 'I']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, evidence can be introduced into a MAP query. The query $$\\arg\\max_{g,i} p(G=g,I=i|S=0)$$\n",
    "would be launched as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAP query, argmax_{g,i} P(G=g, I=i|S=0):')\n",
    "print(inference.map_query(['G', 'I'], evidence = {'S': 0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "## Operations of VE max-sum\n",
    "\n",
    "The operations in this case are equivalent, but slightly different. Marginalization is carried out by taking the maximum value, instead of summing values up. And the combination of factors is performed as a sum, instead of as a product.\n",
    "\n",
    "The sum of factors just sums up the values for those combinations of value that match up in both factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau1 = G.get_cpds('D').to_factor()\n",
    "\n",
    "print(\"Factor over D,C\")\n",
    "print(tau1)\n",
    "print(\"Factor over C\")\n",
    "print(G.get_cpds('C').to_factor())\n",
    "tau1.sum(G.get_cpds('C').to_factor())\n",
    "print(\"Sum of both previous factors:\")\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-marginalization is an operation that takes a factor and returns a copy of it after one variable has been marginalized out. The difference in this case is that marginalization is carried out by taking the maximum value among the repeated rows (combinations of values) that appear after the elimination of that variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Factor over S,I\")\n",
    "tau1=G.get_cpds('S').to_factor()\n",
    "print(tau1)\n",
    "print(\"Max-marginalization of the previous factor (marginalizing out S):\")\n",
    "tau1.maximize(['S'])\n",
    "print(tau1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
