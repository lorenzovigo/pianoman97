{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying your solution, Virtualization and Containerization \n",
    "\n",
    "\n",
    " Virtualization and Containerization  are solutions to the problem of how to get software to run reliably when moved from one computing environment to another. This could be from a developer's laptop to a test environment, from a staging environment into production and perhaps from a physical machine in a data center to a virtual machine in a private or public cloud.\n",
    "\n",
    "## The Virtual Machine\n",
    "\n",
    "A virtual machine (VM) is a completely virtualized environment that only abstracts the physical hardware. A VM comes with its own BIOS, virtualized network adapters, disk storage, CPU and a complete operating system. When a VM boots, it has to go through the entire boot process – just like a normal piece of hardware. While boot times in VMs are often lower than those tied directly to hardware, it can still take several seconds to minutes to boot, depending on several factors.\n",
    "\n",
    "The virtual machine  has been at the center of the cloud computing explosion. The widespread use of virtualization led to amazing changes across the technology industry. The rapid adoption of VMs led to significant changes in processor architecture. Even more than that, the cloud-based platform providers of today could not exist without the virtual machine. Amazon, Digital Ocean, Linode and Joyent are just some of the cloud providers that depend on virtual machines.\n",
    "\n",
    "## The Container\n",
    "\n",
    "While a virtual machine abstracts away the hardware, container abstraction happens at the operating system level. A container consists of an entire runtime environment: an application, plus all its dependencies, libraries and other binaries, and configuration files needed to run it, bundled into one package. By containerizing the application platform and its dependencies, differences in OS distributions and underlying infrastructure are abstracted away. The difference with VM is that a server running three containerized applications runs a single operating system, and each container shares the operating system kernel with the other containers. Shared parts of the operating system are read only, while each container has its own mount (i.e., a way to access the container) for writing. That means the containers are much more lightweight and use far fewer resources than virtual machines.\n",
    "\n",
    "\n",
    "\n",
    "### Containers VS virtual machines\n",
    "\n",
    "\n",
    "A container may be only tens of megabytes in size, whereas a virtual machine with its own entire operating system may be several gigabytes in size.\n",
    "\n",
    "Because of this, a single server can host far more containers than virtual machines. \n",
    "\n",
    "<table>\n",
    "<td colspan=\"3\" width=\"362\">Average Start/Stop Times</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"143\"></td>\n",
    "<td width=\"113\">Start Time</td>\n",
    "<td width=\"105\">Stop Time</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"143\">Docker Containers</td>\n",
    "<td width=\"113\">&lt; 50ms</td>\n",
    "<td width=\"105\">&lt; 50ms</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td width=\"143\">Virtual Machines</td>\n",
    "<td width=\"113\">30 &#8211; 45 seconds</td>\n",
    "<td width=\"105\">5 &#8211; 10 seconds</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Virtual machines may take several minutes to boot up their operating systems and begin running the applications they host, containerized applications can be started almost instantly.\n",
    "\n",
    "\n",
    "Regarding security, a virtual machine is more secure than a container. The main reason is that the virtual machine has the advantage of having hardware isolation. Meanwhile, containers share kernel resources and application libraries. This means that if a virtual machine breaks down it is less likely to take other VMs with it.\n",
    "However, it’s very possible to make a containerized environment highly secure. As with any operating system, you can take traditional security precautions to lock down the environment inside a container. \n",
    "\n",
    "\n",
    "Virtualization and containers may come to be seen as complementary technologies rather than competing ones. That's because containers can be run in lightweight virtual machines to increase isolation and increase security, and because hardware virtualization makes it far easier to manage the hardware infrastructure such as networks, servers and storage which are needed to support containers.\n",
    "\n",
    "### DOCKER\n",
    "\n",
    "\n",
    "Docker is an open-source project that automates the deployment of Linux applications inside software containers: \n",
    "\n",
    "``Docker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run: code, runtime, system tools, system libraries – anything you can install on a server. This guarantees that it will always run the same, regardless of the environment it is running in.``\n",
    "\n",
    "Docker was initially built on top of LXC. Each Docker container’s purpose is to run a single application. As such, the scope for a Docker container is built towards a particular application, as opposed to an entire operating system as is the case for LXC. The file system inside a Docker container provides an environment similar to a VM.\n",
    "\n",
    "Docker further incorporates a sophisticated container management solution that allows for easy scripting and automation. Given the focus on execution time for containerized applications, the ease of scripting is even more important.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Docker:\n",
    "\n",
    "1) Choose your operative system and download the installation program:\n",
    "\n",
    "https://docs.docker.com/engine/installation/\n",
    "\n",
    "2) Open a terminal and test the installation with these commands:\n",
    "\n",
    "    $ docker --version\n",
    "    \n",
    "    $ docker-compose --version\n",
    "\n",
    "    $ docker-machine --version\n",
    "    \n",
    "    $ docker run hello-world\n",
    "    \n",
    "```\n",
    "Unable to find image 'hello-world:latest' locally\n",
    "latest: Pulling from library/hello-world\n",
    "c04b14da8d14: Pull complete \n",
    "Digest: sha256:0256e8a36e2070f7bf2d0b0763dbabdd67798512411de4cdcf9431a1feb60fd9\n",
    "Status: Downloaded newer image for hello-world:latest\n",
    "\n",
    "Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly.\n",
    "\n",
    "To generate this message, Docker took the following steps:\n",
    " 1. The Docker client contacted the Docker daemon.\n",
    " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
    " 3. The Docker daemon created a new container from that image which runs the\n",
    "    executable that produces the output you are currently reading.\n",
    " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
    "    to your terminal.\n",
    "\n",
    "To try something more ambitious, you can run an Ubuntu container with:\n",
    " $ docker run -it ubuntu bash\n",
    "\n",
    "Share images, automate workflows, and more with a free Docker Hub account:\n",
    " https://hub.docker.com\n",
    "\n",
    "For more examples and ideas, visit:\n",
    " https://docs.docker.com/engine/userguide/\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology \n",
    "\n",
    "* **Images**- The blueprints of our application which form the basis of containers. \n",
    "\n",
    "* **Containers** - Created from Docker images and run the actual application. A list of running containers can be seen using the `docker ps` command.\n",
    "\n",
    "* **Docker Daemon** - The background service running on the host that manages building, running and distributing Docker containers. The daemon is the process that runs in the operation system to which clients talk to.\n",
    "\n",
    "* **Docker Client** - The command line tool that allows the user to interact with the daemon. More generally, there can be other forms of clients too - such as Kitematic which provide a GUI to the users.\n",
    "\n",
    "* **Docker Hub** - A registry of Docker images. You can think of the registry as a directory of all available Docker images. If required, one can host their own Docker registries and can use them for pulling images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Docker images are the basis of containers. To see the list of images that are available locally, use the `docker images` command:\n",
    "\n",
    "```\n",
    "REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n",
    "hello-world         latest              c54a2cc56cbb        5 months ago        1.848 kB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, you can think of an image akin to a git repository - images can be committed with changes and have multiple versions. If you don't provide a specific version number, the client defaults to latest. \n",
    "To get a new Docker image you can either get it from a registry (such as the Docker Hub) or create your own. There are tens of thousands of images available on Docker Hub. You can also search for images directly from the command line using `docker search`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important distinction to be aware of when it comes to images is the difference between base and child images.\n",
    "\n",
    "Base images are images that have no parent image, usually images with an OS like ubuntu, busybox or debian.\n",
    "Child images are images that build on base images and add additional functionality.\n",
    "Then there are official and user images, which can be both base and child images.\n",
    "\n",
    "Official images are images that are officially maintained and supported by the folks at Docker. These are typically one word long. In the list of images above, the python, ubuntu, busybox and hello-world images are base images.\n",
    "User images are images created and shared by users like you and me. They build on base images and add additional functionality. Typically, these are formatted as user/image-name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Image of our Flask App :\n",
    "\n",
    "Before we get started creating the image, let's first test that the application works correctly locally. Step one is to clone  the [flask-fooapp](https://github.com/eloipuertas/flask-fooapp) directory, change file `settings.cfg` with your remote mlab mongodb credentials, and install the dependencies:\n",
    "\n",
    "```\n",
    "$ cd flask-fooapp\n",
    "$ pip install -r requirements.txt\n",
    "$ python app.py\n",
    " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
    "```\n",
    "If all goes well, you should see the output as above. Head over to http://localhost:5000 to see the app in action.\n",
    "\n",
    "Looks great doesn't it? The next step now is to create an image with this web app. As mentioned above, all user images are based off of a base image. Since our application is written in Python, the base image we're going to use will be Python 3. More specifically, we are going to use the python:3-onbuild version of the python image.\n",
    "\n",
    "What's the onbuild version you might ask?\n",
    "\n",
    "These images include multiple ONBUILD triggers, which should be all you need to bootstrap most applications. The build will COPY a requirements.txt file, RUN pip install on said file, and then copy the current directory into /usr/src/app.\n",
    "\n",
    "In other words, the onbuild version of the image includes helpers that automate the boring parts of getting an app running. Rather than doing these tasks manually (or scripting these tasks), these images do that work for you. We now have all the ingredients to create our own image - a functioning web app and a base image. How are we going to do that? The answer is - using a **Dockerfile.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerfile\n",
    "\n",
    "A **Dockerfile** is a simple text-file that contains a list of commands that the Docker client calls while creating an image. It's a simple way to automate the image creation process. The best part is that the commands you write in a Dockerfile are almost identical to their equivalent Linux commands. This means you don't really have to learn new syntax to create your own dockerfiles.\n",
    "\n",
    "The application directory does contain a Dockerfile but since we're doing this for the first time, we'll create one from scratch. To start, create a new blank file in our favorite text-editor and save it in the same folder as the flask app by the name of **Dockerfile**.\n",
    "\n",
    "We start with specifying our base image. Use the FROM keyword to do that -\n",
    "```\n",
    "    FROM python:3-onbuild\n",
    "```\n",
    "\n",
    "The next step usually is to write the commands of copying the files and installing the dependencies. Luckily for us, the onbuild version of the image takes care of that. The next thing we need to the specify is the port number that needs to be exposed. Since our flask app is running on port 5000, that's what we'll indicate.\n",
    "\n",
    "```\n",
    "    EXPOSE 5000\n",
    "```\n",
    "\n",
    "\n",
    "The last step is to write the command for running the application, which is simply - python ./app.py. We use the CMD command to do that -\n",
    "\n",
    "```\n",
    "    CMD [\"python\", \"./app.py\"]\n",
    "```\n",
    "\n",
    "The primary purpose of CMD is to tell the container which command it should run when it is started. With that, our Dockerfile is now ready. This is how it looks like -\n",
    "\n",
    "```\n",
    "# our base image\n",
    "FROM python:3-onbuild\n",
    "\n",
    "# specify the port number the container should expose\n",
    "EXPOSE 5000\n",
    "\n",
    "# run the application\n",
    "CMD [\"python\", \"./app.py\"]\n",
    "```\n",
    "\n",
    "Now that we have our **Dockerfile**, we can build our image. The docker build command does the heavy-lifting of creating a Docker image from a Dockerfile.\n",
    "\n",
    "Before you run the command yourself, make sure to replace my username with yours. This username should be the same one you created when you registered on `Docker hub`. If you haven't done that yet, please go ahead and create an account. The docker build command is quite simple - it takes an optional tag name with -t and a location of the directory containing the Dockerfile.\n",
    "\n",
    "docker build -t eloipuertas/fooapp .\n",
    "\n",
    "If you don't have the python:3-onbuild image, the client will first pull the image and then create your image. Hence, your output from running the command will look different from mine. Look carefully and you'll notice that the on-build triggers were executed correctly. If everything went well, your image should be ready! Run docker images and see if your image shows.\n",
    "\n",
    "The last step in this section is to run the image and see if it actually works (replacing my username with yours). The option -p redirects the port 5000 inside docker container to 5000 in your local system, thus you should fine your app in http://localhost:5000 Be sure that the host parameter is 0.0.0.0 in your app.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    $ docker run -p 5000:5000 eloipuertas/fooapp\n",
    "    * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "http://localhost:5000/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different Docker registries you can use (you can even host your own). For now, let's use Docker Hub to publish the image. To publish, just type\n",
    "\n",
    "\n",
    "```\n",
    "    docker push eloipuertas/fooapp\n",
    "``` \n",
    "\n",
    "If this is the first time you are pushing an image, the client will ask you to login. Provide the same credentials that you used for logging into `Docker Hub`.\n",
    "\n",
    "```\n",
    "    Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.\n",
    "    Username: eloipuertas\n",
    "    Password:\n",
    "    Login Succeeded\n",
    "```\n",
    "\n",
    "Remember to replace the name of the image tag above with yours. It is important to have the format of username/image_name so that the client knows where to publish.\n",
    "\n",
    "Once that is done, you can view your image on Docker Hub. For example, here's the [web page](https://hub.docker.com/r/eloipuertas/fooapp/)  for my image.\n",
    "\n",
    "\n",
    "Now that your image is online, anyone who has docker installed can play with your app by typing just a single command.\n",
    "\n",
    "```\n",
    "    $ docker run -p 5000:5000 eloipuertas/fooapp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heroku integration.\n",
    "\n",
    "The integration of docker containers with Heroku PaaS is still in beta.\n",
    "However, here you can follow the simple steps to push a docker container to Heroku:\n",
    "https://devcenter.heroku.com/articles/container-registry-and-runtime#dockerfile-commands-and-runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-container Environments\n",
    "\n",
    "In this section we are going to spend some time learning how to Dockerize applications which rely on different services to run.\n",
    "\n",
    "A complex distributed system normally relays on several services. Is a good idea to have each service in a different container. Each service is likely to have different resource needs and those needs might grow at different rates. By separating the services into different containers, we can compose each service using the most appropriate instance type based on different resource needs. This also plays in very well with the whole microservices movement.\n",
    "\n",
    "In our example, we had two different services: the flask web application, and a mongodb database, hosted in mlab. From now, we will use a local database and we will containerize it.\n",
    "\n",
    "Great, so we need two containers. We've already built our own Flask container in the previous section. And for MongoDB, let's see if we can find something on the hub.\n",
    "\n",
    "`$ docker search mongo`\n",
    "```\n",
    "mongo                          MongoDB document databases provide high av...   2658      [OK]       \n",
    "mongo-express                  Web-based MongoDB admin interface, written...   91        [OK]       \n",
    "\n",
    "```\n",
    "\n",
    "Let's run the mongo deamon in the default port 27017.\n",
    "\n",
    "`$ docker run -dp 27017:27017 mongo` \n",
    "\n",
    "We can see if it is running or not by executing:\n",
    "\n",
    "`docker ps`\n",
    "\n",
    "```\n",
    "CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS              PORTS                      NAMES\n",
    "2d5319f20c8f        mongo                \"/entrypoint.sh mongo\"   34 minutes ago      Up 34 minutes       0.0.0.0:27017->27017/tcp   goofy_aryabhata\n",
    "d9b73ea079a5        eloipuertas/fooapp   \"python ./app.py\"        39 minutes ago      Up 39 minutes       0.0.0.0:8000->5000/tcp     lonely_morse\n",
    "```\n",
    "\n",
    "So we have one Mongo container running on 0.0.0.0:27017 port which we can directly access. If we can tell our Flask app to connect to this URL, it should be able to connect and talk to db, right? Let's change our settings.cfg file in order to put the local address of our mongodb database. \n",
    "\n",
    "```\n",
    "#MONGO_DBNAME = 'ads'\n",
    "#MONGO_URI = \"mongodb://eloi:testing@ds057066.mlab.com:57066/ads\"\n",
    "MONGO_DBNAME = 'foodb'\n",
    "MONGO_URI = \"mongodb://db:27017/foodb\"\n",
    "\n",
    "```\n",
    "\n",
    "Create a new image called fooapp-local with this changes:\n",
    "\n",
    "    docker build -t eloipuertas/fooapp-local . \n",
    "\n",
    "Now, let's ` docker push eloipuertas/fooapp-local ` and `docker kill <CONTAINER_ID>` the previous containers, and let's try to run: \n",
    "\n",
    "    docker run -p 5000:5000 eloipuertas/fooapp-local\n",
    "    \n",
    "    \n",
    "Try to go to the web page: localhost:5000/\n",
    "WAT? It doesn't work! Why?\n",
    "\n",
    "    ServerSelectionTimeoutError: db:27017: [Errno -2] Name or service not known\n",
    "\n",
    "Seems that db server is not known by the web app container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Docker Network\n",
    "\n",
    "Let's see the docker network how is working. When docker is installed, it creates three networks automatically:\n",
    "\n",
    "    docker network ls\n",
    "    \n",
    "The bridge network is the network in which containers are run by default. So that means that when I ran the MONGO container, it was running in this bridge network. To validate this, let's inspect the network\n",
    "\n",
    "    docker network inspect bridge\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"Name\": \"bridge\",\n",
    "        \"Id\": \"7a3fda3105361b3c820fc5b5ad26b7b4e5526fb02274946ee29969f8a4ccbfa5\",\n",
    "        \"Scope\": \"local\",\n",
    "        \"Driver\": \"bridge\",\n",
    "        \"EnableIPv6\": false,\n",
    "        \"IPAM\": {\n",
    "            \"Driver\": \"default\",\n",
    "            \"Options\": null,\n",
    "            \"Config\": [\n",
    "                {\n",
    "                    \"Subnet\": \"172.17.0.0/16\",\n",
    "                    \"Gateway\": \"172.17.0.1\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"Internal\": false,\n",
    "        \"Containers\": {\n",
    "            \"49a25c3933e4ae3553bd76fc3ebd7776589c2d9f3e15424baff3ea9f99b1be20\": {\n",
    "                \"Name\": \"thirsty_varahamihira\",\n",
    "                \"EndpointID\": \"562dbe9da0cfa9b8c6871d3cad5aa495149846ccbf3580c212206d246e5943dd\",\n",
    "                \"MacAddress\": \"02:42:ac:11:00:03\",\n",
    "                \"IPv4Address\": \"172.17.0.3/16\",\n",
    "                \"IPv6Address\": \"\"\n",
    "            },\n",
    "            \"ac498f047befe85cd8a4513602812012af5ad5cc73b149498a78f9538e82272a\": {\n",
    "                \"Name\": \"nostalgic_curran\",\n",
    "                \"EndpointID\": \"a358795772439dd75d9ad6892da86dcc6ce2d589b965b121fba1fa3069c247e7\",\n",
    "                \"MacAddress\": \"02:42:ac:11:00:02\",\n",
    "                \"IPv4Address\": \"172.17.0.2/16\",\n",
    "                \"IPv6Address\": \"\"\n",
    "            }\n",
    "        },\n",
    "        \"Options\": {\n",
    "            \"com.docker.network.bridge.default_bridge\": \"true\",\n",
    "            \"com.docker.network.bridge.enable_icc\": \"true\",\n",
    "            \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n",
    "            \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\",\n",
    "            \"com.docker.network.bridge.name\": \"docker0\",\n",
    "            \"com.docker.network.driver.mtu\": \"1500\"\n",
    "        },\n",
    "        \"Labels\": {}\n",
    "    }\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "You can see that our containers are listed under the Containers section in the output. What we also see is the IP address thesr container have been allotted - 172.17.0.2, 172.17.0.3. Docker allows us to define our own networks while keeping them isolated. \n",
    "\n",
    "Let's first go ahead and create our own network.\n",
    "\n",
    "    $ docker network create fooapp\n",
    "\n",
    "Now that we have a network, we can launch our containers inside this network using the --net flag. Let's do that - but first, we will stop our  containers that are running in the bridge (default) network.\n",
    "```\n",
    "$ docker stop $(docker ps -q)\n",
    "\n",
    "```\n",
    "\n",
    "We will do the same thing as earlier but this time we gave our Mongo container a name db. \n",
    "\n",
    "    docker run -dp 27017:27017 --net fooapp  --name db mongo\n",
    "    \n",
    "Let's launch our Flask container now:\n",
    "\n",
    "   docker run -p 5000:5000 --net fooapp  --name web eloipuertas/fooapp-local \n",
    "   \n",
    "It works, but there is not products!! We have to link our local directory containing data with the container directory. Firt we have to remove the db container and run it again with the volume parameter, which links de local path to the database with the container path.\n",
    "\n",
    "   docker rm -f db\n",
    "   \n",
    "   docker rm -f web\n",
    "   \n",
    "   docker run -dp 27017:27017 -v /Data/db:/data/db --net fooapp  --name db mongo\n",
    "   \n",
    "   docker run -p 5000:5000 --net fooapp  --name web eloipuertas/fooapp-local \n",
    "   \n",
    "   Now works perfectly!\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Compose\n",
    "\n",
    "Compose is a tool that is used for defining and running multi-container Docker apps in an easy way. It provides a configuration file called **docker-compose.yml** that can be used to bring up an application and the suite of services it depends on with just one command.\n",
    "Docker-Compose is already installed with the docker bundle installation.\n",
    "The syntax for the yml is quite simple and the repo already contains the docker-compose file that we'll be using.\n",
    "\n",
    "Let's see if we can create a docker-compose.yml file for our  webapp.\n",
    "\n",
    "```\n",
    "version: \"2\"\n",
    "services:\n",
    "  db:\n",
    "    image: mongo\n",
    "    ports:\n",
    "      - \"27017:27017\"\n",
    "    volumes:\n",
    "      - /Data/db:/data/db\n",
    "  web:\n",
    "    image: eloipuertas/fooapp-local\n",
    "    command: python app.py\n",
    "    ports:\n",
    "      - \"5000:5000\"\n",
    "    volumes:\n",
    "      - .:/code\n",
    "```\n",
    "\n",
    "Let me breakdown what the file above means. At the parent level, we define the names of our services - mb and web. For each service, that Docker needs to run, we can add additional parameters out of which image is required. For *mb*, we just refer to the mongo image available on the Docker Hub. For our Flask app, we refer to the image that we built at the beginning of this section.\n",
    "\n",
    "Via other parameters such as command and ports we provide more information about the container. The volumes parameter specifies a mount point in our web container where the code will reside. This is purely optional and is useful if you need access to logs etc. Refer to the [online](https://docs.docker.com/compose/compose-file/) reference to learn more about the parameters this file supports.\n",
    "\n",
    "    Note: You must be inside the directory with the docker-compose.yml file in order to execute most Compose commands.\n",
    "\n",
    "Great! Now the file is ready, let's see *docker-compose* in action. But before we start, we need to make sure the ports are free. So if you have the Flask and MB containers running, lets turn all them off.\n",
    "\n",
    "    docker stop $(docker ps -q)\n",
    "    dd0ea55a4326\n",
    "    53882829b21e\n",
    "    \n",
    "    \n",
    "Now we can run docker-compose. Navigate to the fooapp directory and run `docker-compose up`\n",
    "\n",
    "```\n",
    "docker-compose up\n",
    "Creating network \"flaskfooapp_default\" with the default driver\n",
    "Creating flaskfooapp_mb_1\n",
    "Creating flaskfooapp_web_1\n",
    "Attaching to flaskfooapp_web_1, flaskfooapp_mb_1\n",
    "\n",
    "```\n",
    "\n",
    "Head over to the IP to see your app live. That was amazing wasn't it? Just few lines of configuration and we have two Docker containers running successfully in unison. Let's stop the services and re-run in detached mode:\n",
    "\n",
    "```\n",
    "    docker-compose stop\n",
    "    docker-compose up -d\n",
    "\n",
    "```\n",
    "\n",
    "We can remove all the docker-compose infrastructure using \n",
    "```\n",
    "    docker-compose down\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted from: https://prakhar.me/docker-curriculum/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
