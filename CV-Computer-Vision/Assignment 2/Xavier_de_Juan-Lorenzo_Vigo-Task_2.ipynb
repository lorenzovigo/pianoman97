{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRsW6LK63lnx"
      },
      "source": [
        "---\n",
        "# FIRST NOTES\n",
        "- Sample weights for each group of users with more than X members (create all possible groups)\n",
        "- Provar d'usar el backbone inception resnet\n",
        "- Final layer changes\n",
        "- Evaluar en validation\n",
        "\n",
        "- Add sample weights to each experiment training\\\n",
        "Exp 1: Resnet weights imagenet + regression layer - 1 training step\\\n",
        "Exp 2: InceptionResnet weights imagenet + regression layer - 1 training step\\\n",
        "Exp 3: Take the best backbone and add some layers at top - 1 training step\\\n",
        "Exp 4: Repeat 3 using two training steps (freeze backbone + full)\\\n",
        "Exp 5: Repeat 3 using two training steps (full + freeze backbone)\\\n",
        "Exp 6: Repeat 3 using three training steps (freeze backbone + freeze top + full)\\\n",
        "Exp 7: Based on the results get the best and try to set a bias initializer\\\n",
        "Exp 8: Change optimizer, loss, learning rate, batch size\\\n",
        "Exp 9: Change the sample weights, use less groups (e.g. excluding gender that is already balanced)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcyTTvq03ln0"
      },
      "source": [
        "# **The Problem: Automatic Apparent Age Estimation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxeXArCf3ln0"
      },
      "source": [
        "# Pre-requisites:\n",
        "Installing tensorflow-gpu (GPU) and OpenCv.\n",
        "Check GPU usage instructions [here](https://research.google.com/colaboratory/faq.html#gpu-availability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h7p5a8k3ln0",
        "outputId": "f6729348-79e9-4fe4-d75c-3f60ff9dcf8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.4.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (2.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (0.15.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (1.12)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (3.19.4)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (1.32.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorflow-gpu==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.0.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (60.7.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (4.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (5.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.0) (4.11.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.26.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (2021.10.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.2.0)\n",
            "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the '/home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: opencv-python in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (4.5.5.62)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from opencv-python) (1.19.5)\n",
            "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the '/home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: h5py in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from h5py) (1.19.5)\n",
            "Requirement already satisfied: six in /home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/lib/python3.8/site-packages (from h5py) (1.15.0)\n",
            "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the '/home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/cv-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu==2.4.0\n",
        "!pip install opencv-python\n",
        "!pip install h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s2ClJ323ln1"
      },
      "source": [
        "---\n",
        "# Downloading and decompressing the Appa-Real Age Dataset [(source)](http://chalearnlap.cvc.uab.es/challenge/13/track/13/description/)\n",
        "- As default, RGB images (cropped faces) are in the range of [0, 255], and labels are in the range of ~0.9 to ~90 (years old).\n",
        "- The data is divided in train, validation and test set. \n",
        "- Matadata is also provided\n",
        "  - gender: male / female \n",
        "  - ethnicity: asian / afroamerican / caucasian\n",
        "  - facial expression: neutral / slightlyhappy / happy / oth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BIgV6loN3ln1"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnYUqIeV3ln2",
        "outputId": "d68ed5f2-c427-4db2-916f-713d2af84130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-03-26 11:16:29--  https://data.chalearnlap.cvc.uab.cat/Colab_2021/app_data.zip\n",
            "Resolving data.chalearnlap.cvc.uab.cat (data.chalearnlap.cvc.uab.cat)... 158.109.8.102\n",
            "Connecting to data.chalearnlap.cvc.uab.cat (data.chalearnlap.cvc.uab.cat)|158.109.8.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 799021037 (762M) [application/zip]\n",
            "Saving to: ‘app_data.zip’\n",
            "\n",
            "app_data.zip        100%[===================>] 762.00M  12.1MB/s    in 67s     \n",
            "\n",
            "2022-03-26 11:17:38 (11.4 MB/s) - ‘app_data.zip’ saved [799021037/799021037]\n",
            "\n",
            "Data decompressed successfully\n"
          ]
        }
      ],
      "source": [
        "# downloading the data\n",
        "!wget https://data.chalearnlap.cvc.uab.cat/Colab_2021/app_data.zip\n",
        "\n",
        "with ZipFile('app_data.zip','r') as zipp:\n",
        "   zipp.extractall()\n",
        "   print('Data decompressed successfully')\n",
        "\n",
        "# removing the .zip file after extraction to clean space\n",
        "!rm app_data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr3xIewE3ln2"
      },
      "source": [
        "# Loading the train/validation data, and re-scaling the labels to [0..1]\n",
        "- X_[train,valid,test] = Face images\n",
        "- Y_[train,valid,test] = Ground truth \n",
        "- M_[train,valid,test] = Metadata (gender, ethnicicy, facial expression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0epwUQp3ln3",
        "outputId": "81ac4c92-764d-48a5-e054-0a1f10a7b21f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data size and shape (4065, 224, 224, 3)\n",
            "Train labels size and shape (4065,)\n",
            "Train metadata size and shape (4065, 3)\n",
            "----\n",
            "Valid data size and shape (1482, 224, 224, 3)\n",
            "Valid labels size and shape (1482,)\n",
            "Valid metadata size and shape (1482, 3)\n",
            "----\n",
            "Test data size and shape (1978, 224, 224, 3)\n",
            "Test labels size and shape (1978,)\n",
            "Test metadata size and shape (1978, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# loading the train data\n",
        "X_train = np.load('./data/data_train.npy')\n",
        "Y_train = np.load('./data/labels_train.npy')\n",
        "M_train = np.load('./data/meta_data_train.npy')\n",
        "\n",
        "# loading the validation data\n",
        "X_valid = np.load('./data/data_valid.npy')\n",
        "Y_valid = np.load('./data/labels_valid.npy')\n",
        "M_valid = np.load('./data/meta_data_valid.npy')\n",
        "\n",
        "# loading the test data\n",
        "X_test = np.load('./data/data_test.npy')\n",
        "Y_test = np.load('./data/labels_test.npy')\n",
        "M_test = np.load('./data/meta_data_test.npy')\n",
        "\n",
        "# train labels are real numbers, ranging from ~0.9 to ~89 (years old);\n",
        "# we will re-scale the labels to [0,1] by using a normalization factor of 100,\n",
        "# assuming there is no sample with age > 100.\n",
        "Y_train = Y_train/100\n",
        "Y_valid = Y_valid/100\n",
        "# Y_test = Y_test/100 # -> we don't normalize the test labels as we will evaluate \n",
        "                      # them using the raw data, i.e., the apparent age values\n",
        "\n",
        "print('Train data size and shape', X_train.shape)\n",
        "print('Train labels size and shape', Y_train.shape)\n",
        "print('Train metadata size and shape', M_train.shape)\n",
        "print('----')\n",
        "print('Valid data size and shape', X_valid.shape)\n",
        "print('Valid labels size and shape', Y_valid.shape)\n",
        "print('Valid metadata size and shape', M_valid.shape)\n",
        "print('----')\n",
        "print('Test data size and shape', X_test.shape)\n",
        "print('Test labels size and shape', Y_test.shape)\n",
        "print('Test metadata size and shape', M_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFsA06jt3ln3"
      },
      "source": [
        "---\n",
        "# Download a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S4MvMwao3ln4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-26 18:36:58.312940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wraBxfk3ln4"
      },
      "source": [
        "## Download ResNet50 model pre-trained on faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH53hh9J3ln4",
        "outputId": "0db768a3-6947-413b-9d41-8725f4e75371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-03-26 18:36:59--  https://data.chalearnlap.cvc.uab.cat/Colab_2021/model.zip\n",
            "S'està resolent data.chalearnlap.cvc.uab.cat (data.chalearnlap.cvc.uab.cat)... 158.109.8.102\n",
            "S'està connectant a data.chalearnlap.cvc.uab.cat (data.chalearnlap.cvc.uab.cat)|158.109.8.102|:443... conectat.\n",
            "HTTP: s'ha enviat la petició, s'està esperant una resposta... 200 OK\n",
            "Mida: 107893665 (103M) [application/zip]\n",
            "S'està desant a: «model.zip»\n",
            "\n",
            "model.zip             3%[                    ]   3,12M  1,47MB/s               ^C\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'ZipFile' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/Assignments/Assignment2/CV_Ass2.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/Assignments/Assignment2/CV_Ass2.ipynb#ch0000012?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mwget https://data.chalearnlap.cvc.uab.cat/Colab_2021/model.zip\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/Assignments/Assignment2/CV_Ass2.ipynb#ch0000012?line=3'>4</a>\u001b[0m \u001b[39m# decompressing the data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/Assignments/Assignment2/CV_Ass2.ipynb#ch0000012?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m ZipFile(\u001b[39m'\u001b[39m\u001b[39mmodel.zip\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m zipp:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/Assignments/Assignment2/CV_Ass2.ipynb#ch0000012?line=5'>6</a>\u001b[0m    zipp\u001b[39m.\u001b[39mextractall()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xavi/Documents/MasterDataScience/subject_repos/UB-DS-CV/Assignments/Assignment2/CV_Ass2.ipynb#ch0000012?line=6'>7</a>\u001b[0m    \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mModel decompressed successfully\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ZipFile' is not defined"
          ]
        }
      ],
      "source": [
        "# downloading the data\n",
        "!wget https://data.chalearnlap.cvc.uab.cat/Colab_2021/model.zip\n",
        "\n",
        "# decompressing the data\n",
        "with ZipFile('model.zip','r') as zipp:\n",
        "   zipp.extractall()\n",
        "   print('Model decompressed successfully')\n",
        "\n",
        "# removing the .zip file after extraction  to clean space\n",
        "!rm model.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aa3EEz33ln4"
      },
      "source": [
        "## Load the pre-trained ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HKRi9TA3ln5",
        "outputId": "2cbb1233-5e82-4be1-ee47-70a3532cd7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "base_input (InputLayer)         [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        base_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dim_proj (Dense)                (None, 512)          1049088     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "classifier_low_dim (Dense)      (None, 8631)         4419072     dim_proj[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 29,029,312\n",
            "Trainable params: 28,976,192\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "MODEL_NAME = 'resnet'\n",
        "\n",
        "# loading the pretrained model\n",
        "model = tf.keras.models.load_model('./model/weights.h5')\n",
        "\n",
        "# print the model summary\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NSyNEbT3ln5"
      },
      "source": [
        "## Load InceptionResnet from keras pre-trained on imagenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wFJRihQ53ln5",
        "outputId": "e8166904-6e9f-4239-a1c2-d61d97f599bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-26 12:37:18.588810: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-03-26 12:37:18.589424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-26 12:37:18.612957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-26 12:37:18.613076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:2b:00.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
            "coreClock: 1.852GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
            "2022-03-26 12:37:18.613089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-03-26 12:37:18.615283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-03-26 12:37:18.615303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-03-26 12:37:18.630151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-03-26 12:37:18.630391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-03-26 12:37:18.630455: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.5/lib64\n",
            "2022-03-26 12:37:18.630851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-03-26 12:37:18.630918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-03-26 12:37:18.630923: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2022-03-26 12:37:18.631451: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-03-26 12:37:18.631468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-03-26 12:37:18.631471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"inception_resnet_v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 96)   18432       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 64)   12288       average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 96)   288         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 64)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 96)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 48)   13824       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 48)   144         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 48)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 32)   9216        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 64)   27648       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 64)   192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 64)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
            "                                                                 block35_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 48)   13824       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 48)   144         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 48)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 32)   9216        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 64)   27648       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 32)   96          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_18[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
            "                                                                 block35_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 48)   13824       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 48)   144         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 48)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 35, 35, 32)   9216        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 35, 35, 64)   27648       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 32)   96          conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 35, 35, 64)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 32)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 35, 35, 64)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_24[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
            "                                                                 block35_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 35, 35, 48)   13824       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 35, 35, 48)   144         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 35, 35, 48)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 35, 35, 32)   9216        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 35, 35, 64)   27648       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 35, 35, 32)   96          conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 35, 35, 64)   192         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 35, 35, 32)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 35, 35, 64)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_30[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
            "                                                                 block35_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 35, 35, 32)   96          conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 35, 35, 48)   13824       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 35, 35, 32)   96          conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 35, 35, 48)   144         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 35, 35, 32)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 35, 35, 48)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 35, 35, 32)   9216        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 35, 35, 64)   27648       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 35, 35, 32)   96          conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 35, 35, 32)   96          conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 35, 35, 64)   192         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 35, 35, 32)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 35, 35, 32)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 35, 35, 64)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_36[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
            "                                                                 block35_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 35, 35, 32)   96          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 35, 35, 32)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 35, 35, 48)   13824       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 35, 35, 48)   144         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 35, 35, 32)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 35, 35, 48)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 35, 35, 32)   9216        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 35, 35, 64)   27648       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 35, 35, 32)   96          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 35, 35, 32)   96          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 35, 35, 64)   192         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 35, 35, 32)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 35, 35, 32)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 35, 35, 64)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_42[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
            "                                                                 block35_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 35, 35, 32)   96          conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 35, 35, 32)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 35, 35, 48)   13824       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 35, 35, 32)   96          conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 35, 35, 48)   144         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 35, 35, 32)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 35, 35, 48)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 35, 35, 32)   9216        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 35, 35, 64)   27648       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 35, 35, 32)   96          conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 35, 35, 32)   96          conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 35, 35, 64)   192         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 35, 35, 32)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 35, 35, 32)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 35, 35, 64)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_48[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
            "                                                                 block35_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 35, 35, 32)   96          conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 35, 35, 32)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 35, 35, 48)   13824       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 35, 35, 32)   96          conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 35, 35, 48)   144         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 35, 35, 32)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 35, 35, 48)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 35, 35, 32)   9216        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 35, 35, 64)   27648       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 35, 35, 32)   96          conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 35, 35, 32)   96          conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 35, 35, 64)   192         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 35, 35, 32)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 35, 35, 32)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 35, 35, 64)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_54[0][0]              \n",
            "                                                                 activation_56[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
            "                                                                 block35_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 35, 35, 32)   96          conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 35, 35, 32)   0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 35, 35, 48)   13824       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 35, 35, 32)   96          conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 35, 35, 48)   144         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 35, 35, 32)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 35, 35, 48)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 35, 35, 32)   9216        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 35, 35, 64)   27648       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 35, 35, 32)   96          conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 35, 35, 32)   96          conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 35, 35, 64)   192         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 35, 35, 32)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 35, 35, 32)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 35, 35, 64)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_60[0][0]              \n",
            "                                                                 activation_62[0][0]              \n",
            "                                                                 activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
            "                                                                 block35_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 35, 35, 32)   96          conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 35, 35, 32)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 35, 35, 48)   13824       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 35, 35, 32)   96          conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 35, 35, 48)   144         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 35, 35, 32)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 35, 35, 48)   0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 35, 35, 32)   9216        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 35, 35, 64)   27648       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 35, 35, 32)   96          conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 35, 35, 32)   96          conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 35, 35, 64)   192         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 35, 35, 32)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 35, 35, 32)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 35, 35, 64)   0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_66[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
            "                                                                 block35_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 35, 35, 256)  768         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 35, 35, 256)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 35, 35, 256)  589824      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 35, 35, 256)  768         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 35, 35, 256)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 17, 17, 384)  884736      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 384)  1152        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 17, 17, 384)  1152        conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 384)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 17, 17, 384)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_72[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 17, 17, 128)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 17, 17, 160)  143360      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 17, 17, 160)  480         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 17, 17, 160)  0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 17, 17, 192)  215040      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 17, 17, 192)  576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 17, 17, 192)  576         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 17, 17, 192)  0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 17, 17, 192)  0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_76[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
            "                                                                 block17_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 17, 17, 128)  384         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 17, 17, 128)  0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 17, 17, 160)  143360      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 17, 17, 160)  480         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 17, 17, 160)  0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 17, 17, 192)  215040      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 17, 17, 192)  576         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 17, 17, 192)  0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_80[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
            "                                                                 block17_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 17, 17, 128)  384         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 17, 17, 128)  0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 17, 17, 160)  143360      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 17, 17, 160)  480         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 17, 17, 160)  0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 17, 17, 192)  215040      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 17, 17, 192)  576         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 17, 17, 192)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_84[0][0]              \n",
            "                                                                 activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
            "                                                                 block17_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 17, 17, 128)  384         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 17, 17, 128)  0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 17, 17, 160)  143360      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 17, 17, 160)  480         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 17, 17, 160)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 17, 17, 192)  215040      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 17, 17, 192)  576         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 17, 17, 192)  0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_88[0][0]              \n",
            "                                                                 activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
            "                                                                 block17_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 17, 17, 128)  384         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 17, 17, 128)  0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 17, 17, 160)  143360      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 17, 17, 160)  480         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 17, 17, 160)  0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 17, 17, 192)  215040      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 17, 17, 192)  576         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 17, 17, 192)  0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 17, 17, 192)  0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_92[0][0]              \n",
            "                                                                 activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
            "                                                                 block17_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 17, 17, 128)  384         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 17, 17, 128)  0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 17, 17, 160)  143360      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 17, 17, 160)  480         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 17, 17, 160)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 17, 17, 192)  215040      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 17, 17, 192)  576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 17, 17, 192)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_96[0][0]              \n",
            "                                                                 activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
            "                                                                 block17_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 17, 17, 128)  384         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 17, 17, 128)  0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 17, 17, 160)  143360      activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 17, 17, 160)  480         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 17, 17, 160)  0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 17, 17, 192)  215040      activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 17, 17, 192)  576         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 17, 17, 192)  576         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 17, 17, 192)  0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_100[0][0]             \n",
            "                                                                 activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
            "                                                                 block17_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 17, 17, 128)  384         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 17, 17, 128)  0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 17, 17, 160)  143360      activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 17, 17, 160)  480         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 17, 17, 160)  0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 17, 17, 192)  215040      activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 17, 17, 192)  576         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 17, 17, 192)  576         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 17, 17, 192)  0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_104[0][0]             \n",
            "                                                                 activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
            "                                                                 block17_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 17, 17, 128)  384         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 17, 17, 128)  0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 17, 17, 160)  143360      activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 17, 17, 160)  480         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 17, 17, 160)  0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 17, 17, 192)  215040      activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 17, 17, 192)  576         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 17, 17, 192)  576         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 17, 17, 192)  0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
            "                                                                 block17_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 17, 17, 128)  384         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 17, 17, 128)  0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 17, 17, 160)  143360      activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 17, 17, 160)  480         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 17, 17, 160)  0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 17, 17, 192)  215040      activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 17, 17, 192)  576         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 17, 17, 192)  576         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 17, 17, 192)  0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 17, 17, 192)  0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_112[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
            "                                                                 block17_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 17, 17, 128)  384         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 17, 17, 128)  0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 17, 17, 160)  143360      activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 17, 17, 160)  480         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 17, 17, 160)  0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 17, 17, 192)  215040      activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 17, 17, 192)  576         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 17, 17, 192)  576         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 17, 17, 192)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 17, 17, 192)  0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_116[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
            "                                                                 block17_11_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 17, 17, 128)  384         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 17, 17, 128)  0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 17, 17, 160)  143360      activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 17, 17, 160)  480         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 17, 17, 160)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 17, 17, 192)  215040      activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 17, 17, 192)  576         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 17, 17, 192)  576         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 17, 17, 192)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 17, 17, 192)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
            "                                                                 block17_12_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 17, 17, 160)  143360      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 17, 17, 160)  480         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 17, 17, 160)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 17, 17, 192)  215040      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
            "                                                                 block17_13_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 17, 17, 160)  143360      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 17, 17, 160)  480         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 17, 17, 160)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 17, 17, 192)  215040      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 17, 17, 192)  576         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 17, 17, 192)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_128[0][0]             \n",
            "                                                                 activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
            "                                                                 block17_14_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 17, 17, 128)  384         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 17, 17, 128)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 17, 17, 160)  143360      activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 17, 17, 160)  480         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 17, 17, 160)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 17, 17, 192)  215040      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 17, 17, 192)  576         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 17, 17, 192)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_132[0][0]             \n",
            "                                                                 activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
            "                                                                 block17_15_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 17, 17, 128)  384         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 17, 17, 128)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 17, 17, 160)  143360      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 17, 17, 192)  215040      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 17, 17, 192)  576         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 17, 17, 192)  576         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 17, 17, 192)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 17, 17, 192)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_136[0][0]             \n",
            "                                                                 activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
            "                                                                 block17_16_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 17, 17, 128)  384         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 17, 17, 128)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 17, 17, 160)  143360      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 17, 17, 160)  480         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 17, 17, 160)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 17, 17, 192)  215040      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 17, 17, 192)  576         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 17, 17, 192)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_140[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
            "                                                                 block17_17_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 17, 17, 128)  384         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 17, 17, 128)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 17, 17, 160)  143360      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
            "                                                                 block17_18_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 17, 17, 128)  384         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 17, 17, 128)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 17, 17, 160)  143360      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 17, 17, 192)  215040      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 17, 17, 192)  576         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 17, 17, 192)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_148[0][0]             \n",
            "                                                                 activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n",
            "                                                                 block17_19_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 17, 17, 128)  384         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 17, 17, 128)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 17, 17, 160)  143360      activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 17, 17, 160)  480         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 17, 17, 160)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 17, 17, 192)  215040      activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_152[0][0]             \n",
            "                                                                 activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
            "                                                                 block17_20_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 17, 17, 256)  768         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 17, 17, 256)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 17, 17, 288)  663552      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 17, 17, 256)  768         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 17, 17, 256)  768         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 17, 17, 288)  864         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 17, 17, 256)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 17, 17, 256)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 17, 17, 288)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 8, 8, 384)    884736      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 8, 8, 288)    663552      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 8, 8, 320)    829440      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 8, 8, 384)    1152        conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 8, 8, 288)    864         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 8, 8, 320)    960         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 8, 8, 384)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 8, 8, 288)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 8, 8, 320)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_157[0][0]             \n",
            "                                                                 activation_159[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 8, 8, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 8, 8, 224)    129024      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 8, 8, 224)    672         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 8, 8, 224)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 8, 8, 256)    172032      activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 8, 8, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 8, 8, 256)    768         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 8, 8, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 8, 8, 256)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_163[0][0]             \n",
            "                                                                 activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
            "                                                                 block8_1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 8, 8, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 8, 8, 224)    129024      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 8, 8, 224)    672         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 8, 8, 224)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 8, 8, 256)    172032      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 8, 8, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 8, 8, 256)    768         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 8, 8, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 8, 8, 256)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_167[0][0]             \n",
            "                                                                 activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
            "                                                                 block8_2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 8, 8, 192)    576         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 8, 8, 192)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 224)    129024      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 8, 8, 224)    672         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 8, 8, 224)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 256)    172032      activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 192)    576         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 8, 8, 256)    768         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 8, 8, 192)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 8, 8, 256)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_171[0][0]             \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
            "                                                                 block8_3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 192)    576         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 8, 8, 192)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 224)    129024      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 8, 8, 224)    672         conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 8, 8, 224)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 256)    172032      activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 8, 8, 192)    576         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 256)    768         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 8, 8, 192)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 8, 8, 256)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_175[0][0]             \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
            "                                                                 block8_4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 192)    576         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 8, 8, 192)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 8, 8, 224)    129024      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 8, 8, 224)    672         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 8, 8, 224)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 8, 8, 256)    172032      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 8, 8, 192)    576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 256)    768         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 8, 8, 192)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 256)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_179[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 192)    576         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 192)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 8, 8, 224)    129024      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 8, 8, 224)    672         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 224)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 8, 8, 256)    172032      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 8, 8, 192)    576         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 8, 8, 256)    768         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 8, 8, 192)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 256)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_183[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 8, 8, 192)    576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 8, 8, 224)    129024      activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 8, 8, 224)    672         conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 8, 8, 224)    0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 8, 8, 256)    172032      activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 8, 8, 256)    768         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 8, 8, 256)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_187[0][0]             \n",
            "                                                                 activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 8, 8, 192)    576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 8, 8, 192)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 8, 8, 224)    129024      activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 8, 8, 224)    672         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 8, 8, 224)    0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 8, 8, 256)    172032      activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 8, 8, 192)    576         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 8, 8, 256)    768         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 8, 8, 192)    0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 8, 8, 256)    0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_191[0][0]             \n",
            "                                                                 activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 8, 8, 192)    576         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 8, 8, 192)    0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 8, 8, 224)    129024      activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 8, 8, 224)    672         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 8, 8, 224)    0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 8, 8, 256)    172032      activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 8, 8, 192)    576         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 8, 8, 256)    768         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 8, 8, 192)    0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 8, 8, 256)    0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, 8, 8, 2080)   0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, 8, 8, 2080)   0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 8, 8, 192)    576         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 8, 8, 192)    0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 8, 8, 224)    129024      activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 8, 8, 224)    672         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 8, 8, 224)    0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 8, 8, 256)    172032      activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 8, 8, 192)    576         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 8, 8, 256)    768         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 8, 8, 192)    0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 8, 8, 256)    0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, 8, 8, 448)    0           activation_199[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, 8, 8, 2080)   933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, 8, 8, 2080)   0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, 8, 8, 1536)   3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, 8, 8, 1536)   4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, 8, 8, 1536)   0           conv_7b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 1536)         0           conv_7b_ac[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         1537000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 55,873,736\n",
            "Trainable params: 55,813,192\n",
            "Non-trainable params: 60,544\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
        "\n",
        "MODEL_NAME = 'inception_resnet'\n",
        "\n",
        "# loading the pretrained model\n",
        "model = InceptionResNetV2(weights='imagenet', include_top=True)\n",
        "\n",
        "# print the model summary\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g31NzPXO3ln5"
      },
      "source": [
        "# Adapting the model to our needs\n",
        "- In summary, we will ignore the last layer 'classifier_low_dim' and will include a few other layers on top of our backbone. Here, we also define the activation function we are going to use as output of the last FC layer (Sigmoid, in the case)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iaFDAAot3ln5"
      },
      "outputs": [],
      "source": [
        "# Get the number of layers in the backbone model\n",
        "BACKBONE_NUM_LAYERS = len(model.layers)-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wSBfq583ln6",
        "outputId": "8fa53161-cc24-4d60-fe96-e938c263abb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "base_input (InputLayer)         [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        base_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dim_proj (Dense)                (None, 512)          1049088     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           dim_proj[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "f_128 (Dense)                   (None, 128)          65664       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "f_32 (Dense)                    (None, 32)           4128        f_128[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "predict (Dense)                 (None, 1)            33          f_32[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 24,680,065\n",
            "Trainable params: 24,626,945\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Get the last layer before the classification one\n",
        "last_layer = model.get_layer(model.layers[-2].name).output\n",
        "\n",
        "# adding a dropout layer to minimize overfiting problems\n",
        "dp_layer = Dropout(0.5)(last_layer)\n",
        "\n",
        "# adding a few hidden FC layers to learn hidden representations\n",
        "fc_128 = Dense(128, activation='relu', name='f_128')(dp_layer)\n",
        "fc_32 = Dense(32, activation='relu', name='f_32')(fc_128)\n",
        "\n",
        "output = Dense(1, activation='sigmoid', name='predict')(fc_32)\n",
        "\n",
        "# building and pringing the final model\n",
        "model = Model(inputs=model.get_layer(model.get_layer(model.layers[0].name).name).output, outputs=output)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usJnvTvK3ln6"
      },
      "source": [
        "---\n",
        "# Define a function to freeze part of the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QDS0_6U73ln6"
      },
      "outputs": [],
      "source": [
        "def freezing_function(model, freeze):\n",
        "    for idx, layer in enumerate(model.layers):\n",
        "        layer.trainable = True\n",
        "        if freeze is not None:\n",
        "            if freeze == 'backbone':\n",
        "                if idx < BACKBONE_NUM_LAYERS:\n",
        "                    layer.trainable = False\n",
        "            if freeze == 'head':\n",
        "                if idx >= BACKBONE_NUM_LAYERS:\n",
        "                    layer.trainable = False\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brfOFz9n3ln6"
      },
      "source": [
        "---\n",
        "# Given the class weights define a function that return the sample weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "p-yJkYiB3ln6"
      },
      "outputs": [],
      "source": [
        "def compute_sample_weights(class_weights, metadata_train):\n",
        "    sample_weights = []\n",
        "\n",
        "    for i in range(0, len(metadata_train)):\n",
        "        sample_weights.append(class_weights['_'.join(metadata_train[i])])\n",
        "\n",
        "    return np.array(sample_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrKRvQ1t3ln7"
      },
      "source": [
        "---\n",
        "# Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P2-QRkxL3ln7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import pickle\n",
        "\n",
        "def training(model, X_train, y_train, metadata_train, X_valid, y_valid, config):\n",
        "    # Train the model (for each train step)\n",
        "    for train_step in range(config['num_training_steps']):\n",
        "        # Apply the freezing function for this step\n",
        "        model = freezing_function(model, config['freeze'][train_step])\n",
        "\n",
        "        # defining the early stop criteria\n",
        "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "        # saving the best model based on val_loss\n",
        "        mc = ModelCheckpoint('temp/best_model_'+str(train_step)+'.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "\n",
        "        # defining the optimizer\n",
        "        model.compile(\n",
        "            optimizer=config['optimizer'][train_step],\n",
        "            loss=config['loss'][train_step],\n",
        "            metrics=config['metrics'][train_step]\n",
        "        )\n",
        "\n",
        "        # compute the sample weights\n",
        "        sample_weights = compute_sample_weights(config['class_weights'], metadata_train)\n",
        "\n",
        "        # training the model\n",
        "        history = model.fit(\n",
        "            X_train, y_train, \n",
        "            validation_data=(X_valid, y_valid), \n",
        "            batch_size=config['batch_size'][train_step], epochs=50, \n",
        "            shuffle=True, verbose=1, callbacks=[es,mc],\n",
        "            sample_weight=sample_weights,\n",
        "        )\n",
        "\n",
        "        # saving training history (for future visualization)\n",
        "        with open('temp/train_history_'+str(train_step)+'.pkl', 'wb') as handle:\n",
        "            pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvPYZTnl3ln7"
      },
      "source": [
        "---\n",
        "# Analyze bias functions\n",
        "\n",
        "# Age Bias ($B_a$) \n",
        "\n",
        "- Evaluates (on the TEST set) how accurate the model is with respect to different age ranges.\n",
        "  - group 1: age < 20\n",
        "  - group 2: 20 <= age < 40\n",
        "  - group 3: 40 <= age < 60\n",
        "  - group 4: 60 <= age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dnsHxz3D3ln7"
      },
      "outputs": [],
      "source": [
        "def age_bias(predictions, gt):\n",
        "  error_g1 = []\n",
        "  error_g2 = []\n",
        "  error_g3 = []\n",
        "  error_g4 = []\n",
        "  for i in range(0,len(gt)):\n",
        "    if(gt[i]<20):\n",
        "      error_g1.append(abs(predictions[i]-gt[i]))\n",
        "    if(gt[i]>=20 and gt[i]<40):\n",
        "      error_g2.append(abs(predictions[i]-gt[i]))\n",
        "    if(gt[i]>=40 and gt[i]<60):\n",
        "      error_g3.append(abs(predictions[i]-gt[i]))\n",
        "    if(gt[i]>=60):\n",
        "      error_g4.append(abs(predictions[i]-gt[i]))\n",
        "\n",
        "  print('=============================')\n",
        "  print('Age analysis:')\n",
        "  print('Size group 1 = %d, MAE = %f' %(len(error_g1), np.mean(error_g1)))\n",
        "  print('Size group 2 = %d, MAE = %f' %(len(error_g2), np.mean(error_g2)))\n",
        "  print('Size group 3 = %d, MAE = %f' %(len(error_g3), np.mean(error_g3)))\n",
        "  print('Size group 4 = %d, MAE = %f' %(len(error_g4), np.mean(error_g4)))\n",
        "\n",
        "  age_bias = (abs(np.mean(error_g1)-np.mean(error_g2)) +\n",
        "            abs(np.mean(error_g1)-np.mean(error_g3)) +\n",
        "            abs(np.mean(error_g1)-np.mean(error_g4)) +\n",
        "            abs(np.mean(error_g2)-np.mean(error_g3)) +\n",
        "            abs(np.mean(error_g2)-np.mean(error_g4)) +\n",
        "            abs(np.mean(error_g3)-np.mean(error_g4)))/6\n",
        "\n",
        "  print('---------')\n",
        "  print('Age bias (Ba) = ', age_bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvfRDF6B3ln7"
      },
      "source": [
        "# Gender Bias ($B_g$) \n",
        "- Evaluates (on the test set) how accurate the model is with respect to different gender.\n",
        "  - group 1: male\n",
        "  - group 2: female"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6UptNjfk3ln7"
      },
      "outputs": [],
      "source": [
        "def gender_bias(predictions, gt, metadata):\n",
        "  error_m = []\n",
        "  error_f = []\n",
        "  for i in range(0,len(gt)):\n",
        "    if(metadata[i][0] == 'female'):\n",
        "      error_f.append(abs(predictions[i]-gt[i]))\n",
        "    else:\n",
        "      error_m.append(abs(predictions[i]-gt[i]))\n",
        "\n",
        "  print('=============================')\n",
        "  print('Gender analysis:')\n",
        "  print('Size group female = %d, MAE = %f' %(len(error_f), np.mean(error_f)))\n",
        "  print('Size group male = %d, MAE = %f' %(len(error_m), np.mean(error_m)))\n",
        "\n",
        "  gender_bias = abs(np.mean(error_f)-np.mean(error_m))\n",
        "\n",
        "  print('---------')\n",
        "  print('Gender bias (Bg) = ', gender_bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJzmQ1AZ3ln7"
      },
      "source": [
        "# Ethnicity Bias ($B_e$)\n",
        "- Evaluates (on the test set) how accurate the model is with respect to different ethnicity categories.\n",
        "  - group 1: asian\n",
        "  - group 2: afroamerican\n",
        "  - group 3: caucasian\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IUAviJf53ln7"
      },
      "outputs": [],
      "source": [
        "def ethnicity_bias(predictions, gt, metadata):\n",
        "  error_as = []\n",
        "  error_af = []\n",
        "  error_ca = []\n",
        "  for i in range(0,len(gt)):\n",
        "    if(metadata[i][1] == 'asian'):\n",
        "      error_as.append(abs(predictions[i]-gt[i]))\n",
        "    if(metadata[i][1] == 'afroamerican'):\n",
        "      error_af.append(abs(predictions[i]-gt[i]))\n",
        "    if(metadata[i][1] == 'caucasian'):\n",
        "      error_ca.append(abs(predictions[i]-gt[i]))\n",
        "\n",
        "  print('=============================')\n",
        "  print('Ethnicity Analysis:')\n",
        "  print('Size group asian = %d, MAE = %f' %(len(error_as), np.mean(error_as)))\n",
        "  print('Size group afroamerican = %d, MAE = %f' %(len(error_af), np.mean(error_af)))\n",
        "  print('Size group caucasian = %d, MAE = %f' %(len(error_ca), np.mean(error_ca)))\n",
        "  \n",
        "  ethnicity_bias = (abs(np.mean(error_as)-np.mean(error_af)) +\n",
        "                   abs(np.mean(error_as)-np.mean(error_ca)) +\n",
        "                   abs(np.mean(error_af)-np.mean(error_ca)))/3\n",
        "\n",
        "  print('---------')\n",
        "  print('Ethnicity bias (Be) = ', ethnicity_bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmY0rnJS3ln8"
      },
      "source": [
        "# Face expression bias ($B_f$)\n",
        "- Evaluates (on the test set) how accurate the model is with respect to different face expression categories.\n",
        "  - group 1: neutral\n",
        "  - group 2: slightlyhappy\n",
        "  - group 3: happy\n",
        "  - group 4: other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vK_P0xf-3ln8"
      },
      "outputs": [],
      "source": [
        "def face_expression_bias(predictions, gt, metadata):\n",
        "  error_h = []\n",
        "  error_s = []\n",
        "  error_n = []\n",
        "  error_o = []\n",
        "  for i in range(0,len(gt)):\n",
        "    if(metadata[i][2]=='happy'):\n",
        "      error_h.append(abs(predictions[i]-gt[i]))\n",
        "    if(metadata[i][2]=='slightlyhappy'):\n",
        "      error_s.append(abs(predictions[i]-gt[i]))\n",
        "    if(metadata[i][2]=='neutral'):\n",
        "      error_n.append(abs(predictions[i]-gt[i]))\n",
        "    if(metadata[i][2]=='other'):\n",
        "      error_o.append(abs(predictions[i]-gt[i]))\n",
        "\n",
        "  print('=============================')\n",
        "  print('Face experession Analysis:')\n",
        "  print('Size group happy = %d, MAE = %f' %(len(error_h), np.mean(error_h)))\n",
        "  print('Size group slightlyhappy = %d, MAE = %f' %(len(error_s), np.mean(error_s)))\n",
        "  print('Size group neutral = %d, MAE = %f' %(len(error_n), np.mean(error_n)))\n",
        "  print('Size group other = %d, MAE = %f' %(len(error_o), np.mean(error_o)))\n",
        "\n",
        "  face_bias = (abs(np.mean(error_h)-np.mean(error_s)) +\n",
        "              abs(np.mean(error_h)-np.mean(error_n)) +\n",
        "              abs(np.mean(error_h)-np.mean(error_o)) +\n",
        "              abs(np.mean(error_s)-np.mean(error_n)) +\n",
        "              abs(np.mean(error_s)-np.mean(error_o)) +\n",
        "              abs(np.mean(error_n)-np.mean(error_o)))/6\n",
        "\n",
        "  print('---------')\n",
        "  print('Face Expression bias (Bf) = ', face_bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtiZevWD3ln8"
      },
      "source": [
        "---\n",
        "# Evaluate function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OJIxZegx3ln8"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, X_test, y_test):\n",
        "    # Make predictions and re-scale (from [0,1] to age range)\n",
        "    predictions = model.predict(X_test, batch_size=32, verbose=1)*100\n",
        "\n",
        "    # evaluating on test data\n",
        "    error = []\n",
        "    for i in range(0,len(y_test)):\n",
        "        error.append(abs(np.subtract(predictions[i][0],y_test[i])))\n",
        "\n",
        "    print('=============================')\n",
        "    print('MAE = %.8f' %(np.mean(error)))\n",
        "\n",
        "    # computing the age bias (model_stage_2)\n",
        "    age_bias(predictions, y_test)\n",
        "\n",
        "    # computing the gender bias (model_stage_2)\n",
        "    gender_bias(predictions, y_test, M_test)\n",
        "\n",
        "    # computing the ethnicity bias (model_stage_2)\n",
        "    ethnicity_bias(predictions, y_test, M_test)\n",
        "\n",
        "    # computing the face bias (model_stage_2)\n",
        "    face_expression_bias(predictions, y_test, M_test)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l99y6sxt3ln8"
      },
      "source": [
        "---\n",
        "# Experiments RUN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkS6A10_3ln8"
      },
      "source": [
        "## Preprocessing the data (face images)\n",
        "- Use the `preprocess_input` function imported for the specific backbone model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zBXKWjsq3ln8"
      },
      "outputs": [],
      "source": [
        "# Run the preprocess_input function to each data sample\n",
        "# train\n",
        "for i in range(0,X_train.shape[0]):\n",
        "    x = X_train[i,:,:,:]\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    X_train[i,] = preprocess_input(x)\n",
        "\n",
        "# validation\n",
        "for i in range(0,X_valid.shape[0]):\n",
        "    x = X_valid[i,:,:,:]\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    X_valid[i,] = preprocess_input(x)  \n",
        "\n",
        "# test\n",
        "for i in range(0,X_test.shape[0]):\n",
        "    x = X_test[i,:,:,:]\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    X_test[i,] = preprocess_input(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "if MODEL_NAME == 'inception_resnet':\n",
        "    # Resize the images to the required size (299, 299, 3)\n",
        "    X_train = tf.image.resize(X_train, (299, 299))\n",
        "    X_valid = tf.image.resize(X_valid, (299, 299))\n",
        "    X_test = tf.image.resize(X_test, (299, 299))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnarzowX3ln9"
      },
      "source": [
        "## Compute class weights and define the training metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nGpbE4iA3ln9"
      },
      "outputs": [],
      "source": [
        "# explore the groups from the data\n",
        "y_train_bin = (Y_train.copy()*100).astype(int)\n",
        "y_train_bin[y_train_bin < 20] = 0\n",
        "y_train_bin[(y_train_bin >= 20) & (y_train_bin < 40)] = 1\n",
        "y_train_bin[(y_train_bin >= 40) & (y_train_bin < 60)] = 2\n",
        "y_train_bin[y_train_bin >= 60] = 3\n",
        "\n",
        "metadata_train = np.concatenate((M_train, y_train_bin[:, np.newaxis]), axis=1)\n",
        "groups, group_counts = np.unique(metadata_train, axis=0, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rBjPBF3p3ln9"
      },
      "outputs": [],
      "source": [
        "class_weights = {\n",
        "    '_'.join(group): (1/g_count) * (group_counts.sum() / 2.0) for group, g_count in zip(groups, group_counts)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItNauvlf3ln9"
      },
      "source": [
        "## Run experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "k6XxmGen3ln9"
      },
      "outputs": [],
      "source": [
        "config = { # Step hyperparameters are arrays of length num_training_steps\n",
        "    'num_training_steps': 2,\n",
        "    'freeze': ['backbone', None],\n",
        "    'optimizer': [\n",
        "        tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "        tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    ],\n",
        "    'loss': [\n",
        "        tf.keras.losses.MeanSquaredError(),\n",
        "        tf.keras.losses.MeanSquaredError()\n",
        "    ],\n",
        "    'metrics': ['mae', 'mae'],\n",
        "    'batch_size': [32, 32],\n",
        "    'class_weights': class_weights,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GIJzfdv3ln9",
        "outputId": "6cf7d21d-c6d3-427d-e329-83ed730e6386"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-26 18:38:01.001206: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2022-03-26 18:38:01.018298: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3699845000 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "128/128 [==============================] - 100s 769ms/step - loss: 7.1079 - mae: 0.3328 - val_loss: 0.2704 - val_mae: 0.2662\n",
            "Epoch 2/50\n",
            "128/128 [==============================] - 97s 759ms/step - loss: 6.3172 - mae: 0.2905 - val_loss: 0.2576 - val_mae: 0.2414\n",
            "Epoch 3/50\n",
            "128/128 [==============================] - 96s 752ms/step - loss: 5.9695 - mae: 0.3007 - val_loss: 0.2586 - val_mae: 0.2484\n",
            "Epoch 4/50\n",
            "128/128 [==============================] - 96s 753ms/step - loss: 5.7277 - mae: 0.2786 - val_loss: 0.2571 - val_mae: 0.2473\n",
            "Epoch 5/50\n",
            "128/128 [==============================] - 94s 739ms/step - loss: 4.7090 - mae: 0.2716 - val_loss: 0.2552 - val_mae: 0.2436\n",
            "Epoch 6/50\n",
            "128/128 [==============================] - 95s 745ms/step - loss: 4.4708 - mae: 0.2761 - val_loss: 0.2532 - val_mae: 0.2388\n",
            "Epoch 7/50\n",
            "128/128 [==============================] - 95s 744ms/step - loss: 5.1350 - mae: 0.2763 - val_loss: 0.2532 - val_mae: 0.2364\n",
            "Epoch 8/50\n",
            "128/128 [==============================] - 95s 746ms/step - loss: 4.4816 - mae: 0.2826 - val_loss: 0.2511 - val_mae: 0.2343\n",
            "Epoch 9/50\n",
            "128/128 [==============================] - 95s 746ms/step - loss: 4.0815 - mae: 0.2734 - val_loss: 0.2486 - val_mae: 0.2284\n",
            "Epoch 10/50\n",
            "128/128 [==============================] - 95s 746ms/step - loss: 4.1959 - mae: 0.2749 - val_loss: 0.2481 - val_mae: 0.2301\n",
            "Epoch 11/50\n",
            "128/128 [==============================] - 95s 741ms/step - loss: 3.8046 - mae: 0.2666 - val_loss: 0.2470 - val_mae: 0.2282\n",
            "Epoch 12/50\n",
            "128/128 [==============================] - 96s 751ms/step - loss: 4.7390 - mae: 0.2627 - val_loss: 0.2465 - val_mae: 0.2258\n",
            "Epoch 13/50\n",
            "128/128 [==============================] - 95s 747ms/step - loss: 3.8061 - mae: 0.2709 - val_loss: 0.2490 - val_mae: 0.2275\n",
            "Epoch 14/50\n",
            "128/128 [==============================] - 94s 737ms/step - loss: 3.5511 - mae: 0.2652 - val_loss: 0.2432 - val_mae: 0.2192\n",
            "Epoch 15/50\n",
            "128/128 [==============================] - 94s 738ms/step - loss: 3.3158 - mae: 0.2558 - val_loss: 0.2419 - val_mae: 0.2145\n",
            "Epoch 16/50\n",
            "128/128 [==============================] - 94s 735ms/step - loss: 3.9856 - mae: 0.2602 - val_loss: 0.2491 - val_mae: 0.2216\n",
            "Epoch 17/50\n",
            "128/128 [==============================] - 94s 737ms/step - loss: 4.2126 - mae: 0.2640 - val_loss: 0.2396 - val_mae: 0.2086\n",
            "Epoch 18/50\n",
            "128/128 [==============================] - 95s 742ms/step - loss: 6.2881 - mae: 0.2498 - val_loss: 0.2413 - val_mae: 0.2092\n",
            "Epoch 19/50\n",
            "128/128 [==============================] - 95s 745ms/step - loss: 3.9423 - mae: 0.2521 - val_loss: 0.2345 - val_mae: 0.1991\n",
            "Epoch 20/50\n",
            "128/128 [==============================] - 95s 745ms/step - loss: 3.1812 - mae: 0.2438 - val_loss: 0.2350 - val_mae: 0.2003\n",
            "Epoch 21/50\n",
            "128/128 [==============================] - 95s 743ms/step - loss: 3.6275 - mae: 0.2447 - val_loss: 0.2307 - val_mae: 0.1945\n",
            "Epoch 22/50\n",
            "128/128 [==============================] - 94s 739ms/step - loss: 3.9887 - mae: 0.2364 - val_loss: 0.2261 - val_mae: 0.1828\n",
            "Epoch 23/50\n",
            "128/128 [==============================] - 95s 742ms/step - loss: 2.9561 - mae: 0.2362 - val_loss: 0.2256 - val_mae: 0.1845\n",
            "Epoch 24/50\n",
            "128/128 [==============================] - 95s 744ms/step - loss: 2.7985 - mae: 0.2296 - val_loss: 0.2277 - val_mae: 0.1844\n",
            "Epoch 25/50\n",
            "128/128 [==============================] - 95s 744ms/step - loss: 3.0362 - mae: 0.2332 - val_loss: 0.2241 - val_mae: 0.1779\n",
            "Epoch 26/50\n",
            "128/128 [==============================] - 94s 738ms/step - loss: 3.3128 - mae: 0.2223 - val_loss: 0.2189 - val_mae: 0.1654\n",
            "Epoch 27/50\n",
            "128/128 [==============================] - 94s 733ms/step - loss: 3.0334 - mae: 0.2241 - val_loss: 0.2184 - val_mae: 0.1649\n",
            "Epoch 28/50\n",
            "128/128 [==============================] - 94s 733ms/step - loss: 2.5292 - mae: 0.2170 - val_loss: 0.2168 - val_mae: 0.1610\n",
            "Epoch 29/50\n",
            "128/128 [==============================] - 94s 733ms/step - loss: 2.6361 - mae: 0.2095 - val_loss: 0.2141 - val_mae: 0.1538\n",
            "Epoch 30/50\n",
            "128/128 [==============================] - 95s 747ms/step - loss: 2.5818 - mae: 0.2012 - val_loss: 0.2129 - val_mae: 0.1505\n",
            "Epoch 31/50\n",
            "128/128 [==============================] - 96s 752ms/step - loss: 2.1556 - mae: 0.1961 - val_loss: 0.2101 - val_mae: 0.1440\n",
            "Epoch 32/50\n",
            "128/128 [==============================] - 98s 765ms/step - loss: 2.1352 - mae: 0.1890 - val_loss: 0.2084 - val_mae: 0.1397\n",
            "Epoch 33/50\n",
            "128/128 [==============================] - 98s 765ms/step - loss: 2.5430 - mae: 0.1851 - val_loss: 0.2075 - val_mae: 0.1375\n",
            "Epoch 34/50\n",
            "128/128 [==============================] - 95s 740ms/step - loss: 2.1988 - mae: 0.1862 - val_loss: 0.2062 - val_mae: 0.1335\n",
            "Epoch 35/50\n",
            "128/128 [==============================] - 93s 725ms/step - loss: 2.2954 - mae: 0.1834 - val_loss: 0.2065 - val_mae: 0.1339\n",
            "Epoch 36/50\n",
            "128/128 [==============================] - 94s 739ms/step - loss: 2.0944 - mae: 0.1709 - val_loss: 0.2044 - val_mae: 0.1285\n",
            "Epoch 37/50\n",
            "128/128 [==============================] - 94s 738ms/step - loss: 1.6566 - mae: 0.1714 - val_loss: 0.2038 - val_mae: 0.1270\n",
            "Epoch 38/50\n",
            "128/128 [==============================] - 93s 728ms/step - loss: 1.7447 - mae: 0.1692 - val_loss: 0.2031 - val_mae: 0.1247\n",
            "Epoch 39/50\n",
            "128/128 [==============================] - 94s 733ms/step - loss: 1.7288 - mae: 0.1664 - val_loss: 0.2019 - val_mae: 0.1213\n",
            "Epoch 40/50\n",
            "128/128 [==============================] - 93s 727ms/step - loss: 1.9949 - mae: 0.1604 - val_loss: 0.2006 - val_mae: 0.1176\n",
            "Epoch 41/50\n",
            "128/128 [==============================] - 92s 723ms/step - loss: 1.8209 - mae: 0.1603 - val_loss: 0.1998 - val_mae: 0.1156\n",
            "Epoch 42/50\n",
            "128/128 [==============================] - 92s 717ms/step - loss: 1.8322 - mae: 0.1575 - val_loss: 0.1989 - val_mae: 0.1132\n",
            "Epoch 43/50\n",
            "128/128 [==============================] - 93s 728ms/step - loss: 1.6980 - mae: 0.1555 - val_loss: 0.1989 - val_mae: 0.1126\n",
            "Epoch 44/50\n",
            "128/128 [==============================] - 92s 723ms/step - loss: 1.6085 - mae: 0.1460 - val_loss: 0.1989 - val_mae: 0.1127\n",
            "Epoch 45/50\n",
            "128/128 [==============================] - 93s 726ms/step - loss: 1.6496 - mae: 0.1502 - val_loss: 0.1985 - val_mae: 0.1113\n",
            "Epoch 46/50\n",
            "128/128 [==============================] - 93s 725ms/step - loss: 1.6862 - mae: 0.1461 - val_loss: 0.1978 - val_mae: 0.1090\n",
            "Epoch 47/50\n",
            "128/128 [==============================] - 93s 724ms/step - loss: 1.6463 - mae: 0.1440 - val_loss: 0.1974 - val_mae: 0.1083\n",
            "Epoch 48/50\n",
            "128/128 [==============================] - 93s 732ms/step - loss: 1.3622 - mae: 0.1415 - val_loss: 0.1976 - val_mae: 0.1089\n",
            "Epoch 49/50\n",
            "128/128 [==============================] - 93s 732ms/step - loss: 1.3918 - mae: 0.1421 - val_loss: 0.1970 - val_mae: 0.1070\n",
            "Epoch 50/50\n",
            "128/128 [==============================] - 94s 737ms/step - loss: 1.5424 - mae: 0.1386 - val_loss: 0.1968 - val_mae: 0.1064\n",
            "Epoch 1/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 2.7890 - mae: 0.1939 - val_loss: 0.2002 - val_mae: 0.1141\n",
            "Epoch 2/50\n",
            "128/128 [==============================] - 394s 3s/step - loss: 2.1034 - mae: 0.1666 - val_loss: 0.1997 - val_mae: 0.1131\n",
            "Epoch 3/50\n",
            "128/128 [==============================] - 396s 3s/step - loss: 1.7525 - mae: 0.1637 - val_loss: 0.1990 - val_mae: 0.1116\n",
            "Epoch 4/50\n",
            "128/128 [==============================] - 387s 3s/step - loss: 1.4374 - mae: 0.1530 - val_loss: 0.1982 - val_mae: 0.1096\n",
            "Epoch 5/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 1.6327 - mae: 0.1507 - val_loss: 0.1984 - val_mae: 0.1090\n",
            "Epoch 6/50\n",
            "128/128 [==============================] - 400s 3s/step - loss: 1.4161 - mae: 0.1443 - val_loss: 0.1976 - val_mae: 0.1068\n",
            "Epoch 7/50\n",
            "128/128 [==============================] - 396s 3s/step - loss: 1.1867 - mae: 0.1413 - val_loss: 0.1972 - val_mae: 0.1065\n",
            "Epoch 8/50\n",
            "128/128 [==============================] - 411s 3s/step - loss: 1.2293 - mae: 0.1339 - val_loss: 0.1971 - val_mae: 0.1057\n",
            "Epoch 9/50\n",
            "128/128 [==============================] - 411s 3s/step - loss: 0.9734 - mae: 0.1305 - val_loss: 0.1973 - val_mae: 0.1064\n",
            "Epoch 10/50\n",
            "128/128 [==============================] - 401s 3s/step - loss: 0.9846 - mae: 0.1267 - val_loss: 0.1964 - val_mae: 0.1026\n",
            "Epoch 11/50\n",
            "128/128 [==============================] - 394s 3s/step - loss: 1.0547 - mae: 0.1299 - val_loss: 0.1964 - val_mae: 0.1032\n",
            "Epoch 12/50\n",
            "128/128 [==============================] - 391s 3s/step - loss: 0.9030 - mae: 0.1261 - val_loss: 0.1964 - val_mae: 0.1031\n",
            "Epoch 13/50\n",
            "128/128 [==============================] - 400s 3s/step - loss: 0.8373 - mae: 0.1219 - val_loss: 0.1958 - val_mae: 0.1014\n",
            "Epoch 14/50\n",
            "128/128 [==============================] - 400s 3s/step - loss: 0.9169 - mae: 0.1185 - val_loss: 0.1974 - val_mae: 0.1052\n",
            "Epoch 15/50\n",
            "128/128 [==============================] - 395s 3s/step - loss: 0.9466 - mae: 0.1179 - val_loss: 0.1951 - val_mae: 0.0992\n",
            "Epoch 16/50\n",
            "128/128 [==============================] - 391s 3s/step - loss: 0.6865 - mae: 0.1120 - val_loss: 0.1949 - val_mae: 0.0984\n",
            "Epoch 17/50\n",
            "128/128 [==============================] - 391s 3s/step - loss: 0.7597 - mae: 0.1113 - val_loss: 0.1946 - val_mae: 0.0976\n",
            "Epoch 18/50\n",
            "128/128 [==============================] - 391s 3s/step - loss: 0.6990 - mae: 0.1090 - val_loss: 0.1941 - val_mae: 0.0960\n",
            "Epoch 19/50\n",
            "128/128 [==============================] - 391s 3s/step - loss: 0.6891 - mae: 0.1042 - val_loss: 0.1942 - val_mae: 0.0963\n",
            "Epoch 20/50\n",
            "128/128 [==============================] - 390s 3s/step - loss: 0.6236 - mae: 0.1022 - val_loss: 0.1941 - val_mae: 0.0960\n",
            "Epoch 21/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.6503 - mae: 0.1059 - val_loss: 0.1940 - val_mae: 0.0955\n",
            "Epoch 22/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.5890 - mae: 0.1021 - val_loss: 0.1935 - val_mae: 0.0940\n",
            "Epoch 23/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.6130 - mae: 0.1014 - val_loss: 0.1936 - val_mae: 0.0942\n",
            "Epoch 24/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.5371 - mae: 0.0952 - val_loss: 0.1931 - val_mae: 0.0927\n",
            "Epoch 25/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.5722 - mae: 0.0958 - val_loss: 0.1931 - val_mae: 0.0926\n",
            "Epoch 26/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.5999 - mae: 0.0932 - val_loss: 0.1931 - val_mae: 0.0926\n",
            "Epoch 27/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.5020 - mae: 0.0914 - val_loss: 0.1929 - val_mae: 0.0918\n",
            "Epoch 28/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.4823 - mae: 0.0884 - val_loss: 0.1925 - val_mae: 0.0905\n",
            "Epoch 29/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.5155 - mae: 0.0911 - val_loss: 0.1924 - val_mae: 0.0899\n",
            "Epoch 30/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.4397 - mae: 0.0872 - val_loss: 0.1921 - val_mae: 0.0890\n",
            "Epoch 31/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.4655 - mae: 0.0854 - val_loss: 0.1923 - val_mae: 0.0892\n",
            "Epoch 32/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.4140 - mae: 0.0830 - val_loss: 0.1921 - val_mae: 0.0881\n",
            "Epoch 33/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.4362 - mae: 0.0823 - val_loss: 0.1917 - val_mae: 0.0868\n",
            "Epoch 34/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.5013 - mae: 0.0815 - val_loss: 0.1923 - val_mae: 0.0892\n",
            "Epoch 35/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.4251 - mae: 0.0800 - val_loss: 0.1919 - val_mae: 0.0881\n",
            "Epoch 36/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.3967 - mae: 0.0761 - val_loss: 0.1917 - val_mae: 0.0867\n",
            "Epoch 37/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.3983 - mae: 0.0771 - val_loss: 0.1919 - val_mae: 0.0874\n",
            "Epoch 38/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.3960 - mae: 0.0766 - val_loss: 0.1915 - val_mae: 0.0863\n",
            "Epoch 39/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.3989 - mae: 0.0755 - val_loss: 0.1915 - val_mae: 0.0866\n",
            "Epoch 40/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.4012 - mae: 0.0752 - val_loss: 0.1912 - val_mae: 0.0850\n",
            "Epoch 41/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.3808 - mae: 0.0706 - val_loss: 0.1923 - val_mae: 0.0898\n",
            "Epoch 42/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.3634 - mae: 0.0696 - val_loss: 0.1911 - val_mae: 0.0846\n",
            "Epoch 43/50\n",
            "128/128 [==============================] - 389s 3s/step - loss: 0.3544 - mae: 0.0690 - val_loss: 0.1909 - val_mae: 0.0839\n",
            "Epoch 44/50\n",
            "128/128 [==============================] - 388s 3s/step - loss: 0.3765 - mae: 0.0674 - val_loss: 0.1910 - val_mae: 0.0840\n",
            "Epoch 45/50\n",
            "128/128 [==============================] - 388s 3s/step - loss: 0.3652 - mae: 0.0700 - val_loss: 0.1910 - val_mae: 0.0839\n",
            "Epoch 46/50\n",
            "128/128 [==============================] - 388s 3s/step - loss: 0.3842 - mae: 0.0704 - val_loss: 0.1909 - val_mae: 0.0830\n",
            "Epoch 47/50\n",
            "128/128 [==============================] - 388s 3s/step - loss: 0.3306 - mae: 0.0662 - val_loss: 0.1906 - val_mae: 0.0822\n",
            "Epoch 48/50\n",
            "128/128 [==============================] - 388s 3s/step - loss: 0.3434 - mae: 0.0652 - val_loss: 0.1905 - val_mae: 0.0814\n",
            "Epoch 49/50\n",
            "128/128 [==============================] - 388s 3s/step - loss: 0.3256 - mae: 0.0640 - val_loss: 0.1905 - val_mae: 0.0814\n",
            "Epoch 50/50\n",
            "128/128 [==============================] - 395s 3s/step - loss: 0.3354 - mae: 0.0657 - val_loss: 0.1906 - val_mae: 0.0821\n",
            "62/62 [==============================] - 34s 537ms/step\n",
            "=============================\n",
            "MAE = 9.06141606\n",
            "=============================\n",
            "Age analysis:\n",
            "Size group 1 = 369, MAE = 8.846796\n",
            "Size group 2 = 1044, MAE = 7.234511\n",
            "Size group 3 = 390, MAE = 10.111352\n",
            "Size group 4 = 175, MAE = 18.072891\n",
            "---------\n",
            "Age bias (Ba) =  5.629949569702148\n",
            "=============================\n",
            "Gender analysis:\n",
            "Size group female = 1020, MAE = 9.240511\n",
            "Size group male = 958, MAE = 8.870729\n",
            "---------\n",
            "Gender bias (Bg) =  0.3697815\n",
            "=============================\n",
            "Ethnicity Analysis:\n",
            "Size group asian = 129, MAE = 8.670160\n",
            "Size group afroamerican = 56, MAE = 7.902730\n",
            "Size group caucasian = 1793, MAE = 9.125755\n",
            "---------\n",
            "Ethnicity bias (Be) =  0.8153505325317383\n",
            "=============================\n",
            "Face experession Analysis:\n",
            "Size group happy = 589, MAE = 9.305626\n",
            "Size group slightlyhappy = 505, MAE = 8.810519\n",
            "Size group neutral = 756, MAE = 9.099318\n",
            "Size group other = 128, MAE = 8.703678\n",
            "---------\n",
            "Face Expression bias (Bf) =  0.3491069475809733\n"
          ]
        }
      ],
      "source": [
        "# Train the model with the given config\n",
        "model = training(model, X_train, Y_train, metadata_train, X_valid, Y_valid, config)\n",
        "\n",
        "predictions = evaluate(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6bV_mOx3ln9"
      },
      "source": [
        "---\n",
        "# Saving the predicted values (on Test set) to be uploaded on Codalab Competition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# save the predictions to a csv file\n",
        "with open('predictions.csv', 'w') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(predictions)\n",
        "\n",
        "# compressing the csv file (to be submitted to codalab as prediction)\n",
        "! zip predictions.zip predictions.csv"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CV_Ass2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "92db24907b656f1a4d8cb5a7c2bba7505f1b45bd873b05b28fbc79e8b65fcf6d"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('cv-env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
